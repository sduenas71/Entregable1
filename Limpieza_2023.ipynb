{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Limpieza y preparación de datos de calidad del aire (Colab)\n",
        "# ============================================================\n",
        "# Requisitos (en una celda aparte si hace falta):\n",
        "# !pip install numbers-parser pandas numpy openpyxl xlrd scikit-learn pyjanitor python-dateutil\n",
        "\n",
        "import os\n",
        "import re\n",
        "import math\n",
        "import warnings\n",
        "from typing import Dict, Tuple, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from dateutil import parser as dtparser\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, KBinsDiscretizer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from IPython.display import display\n",
        "from pandas.api.types import (\n",
        "    is_numeric_dtype,\n",
        "    is_datetime64_any_dtype,\n",
        "    is_bool_dtype,\n",
        "    is_categorical_dtype,\n",
        ")\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# =========================================\n",
        "# 0) Parámetros del usuario / rutas base\n",
        "# =========================================\n",
        "PATH_DATA_NUMBERS = \"/content/DATOS HISTORICOS 2023_2024_TODAS ESTACIONES_ITESM.numbers\"\n",
        "PATH_DATA_XLSX    = \"/content/DATOS HISTORICOS 2023_2024_TODAS ESTACIONES_ITESM.xlsx\"  # usando Excel\n",
        "PATH_ETIQUETAS    = \"/content/Etiquetas.xlsx\"\n",
        "\n",
        "# Si tu archivo está en .numbers, usa READ_NUMBERS=True. Si ya exportaste a .xlsx, pon False.\n",
        "READ_NUMBERS = False  # ← ahora que cambiaste a Excel\n",
        "\n",
        "# ¿Crear variables dummy para categóricas?\n",
        "CREATE_DUMMIES = True\n",
        "\n",
        "# ¿Estrategia de imputación para NA al final del paso de limpieza?\n",
        "#   None            -> no imputar (se deja NaN tras interpolar y ffill/bfill)\n",
        "#   \"median\"        -> imputación por mediana\n",
        "#   \"mean\"          -> imputación por media\n",
        "IMPUTE_STRATEGY = None\n",
        "\n",
        "# ¿Escalado de numéricas?\n",
        "#   None | \"standard\" | \"minmax\"\n",
        "SCALING = \"standard\"\n",
        "\n",
        "# ¿Binning (discretización) de numéricas seleccionadas?\n",
        "#   None | \"quantile\" | \"uniform\"   (usa KBinsDiscretizer)\n",
        "BINNING = None\n",
        "N_BINS  = 5\n",
        "\n",
        "# Columnas esperadas de mediciones (nombres estándar que forzaremos)\n",
        "EXPECTED_COLS = [\n",
        "    \"PM10\",\"PM2.5\",\"O3\",\"NO\",\"NO2\",\"NOx\",\"SO2\",\"CO\",\"RH\",\"WS\",\"TEMP\",\"SR\",\"BP\",\"WD\",\"RAINF\"\n",
        "]\n",
        "\n",
        "# Nombre de columna de tiempo\n",
        "TIME_COL = \"DATETIME\"\n",
        "\n",
        "# =========================================\n",
        "# 1) RANGOS por año (del PDF)\n",
        "# =========================================\n",
        "RANGOS_POR_ANIO: Dict[int, Dict[str, Tuple[float, float]]] = {\n",
        "    2020: {\"PM10\":(0,800),\"PM2.5\":(0,205.94),\"O3\":(0,153),\"NO\":(0,500),\"NO2\":(0,200),\"NOx\":(0,500),\n",
        "           \"SO2\":(0,200),\"CO\":(0,20),\"RH\":(0,100),\"WS\":(0,75),\"TEMP\":(0,41),\"SR\":(0,1),\"BP\":(690,750),\n",
        "           \"WD\":(0,360),\"RAINF\":(0,30)},\n",
        "    2021: {\"PM10\":(0,800),\"PM2.5\":(0,325),\"O3\":(0,175),\"NO\":(0,350),\"NO2\":(0,100),\"NOx\":(0,400),\n",
        "           \"SO2\":(0,300),\"CO\":(0,10),\"RH\":(0,100),\"WS\":(0,40),\"TEMP\":(-6.5,45),\"SR\":(0,1),\n",
        "           \"BP\":(690,740),\"WD\":(0,360),\"RAINF\":(0,80)},\n",
        "    2022: {\"PM10\":(0,999),\"PM2.5\":(0,450),\"O3\":(0,160),\"NO\":(0,400),\"NO2\":(0,175),\"NOx\":(0,420),\n",
        "           \"SO2\":(0,200),\"CO\":(0,8),\"RH\":(0,100),\"WS\":(0,35),\"TEMP\":(-5,45),\"SR\":(0,1.25),\n",
        "           \"BP\":(700,740),\"WD\":(0,360),\"RAINF\":(0,25)},\n",
        "    2023: {\"PM10\":(0,900),\"PM2.5\":(0,800),\"O3\":(0,175),\"NO\":(0,500),\"NO2\":(0,175),\"NOx\":(0,500),\n",
        "           \"SO2\":(0,250),\"CO\":(0,14),\"RH\":(0,100),\"WS\":(0,40),\"TEMP\":(0,45),\"SR\":(0,1),\n",
        "           \"BP\":(690,740),\"WD\":(0,360),\"RAINF\":(0,70)},\n",
        "    2024: {\"PM10\":(0,999),\"PM2.5\":(0,999),\"O3\":(0,180),\"NO\":(0,400),\"NO2\":(0,130),\"NOx\":(0,500),\n",
        "           \"SO2\":(0,150),\"CO\":(0,18),\"RH\":(0,100),\"WS\":(0,38),\"TEMP\":(-4,45.5),\"SR\":(0,1.26),\n",
        "           \"BP\":(687.5,740),\"WD\":(0,360),\"RAINF\":(0,50)},\n",
        "    2025: {\"PM10\":(0,820),\"PM2.5\":(0,350),\"O3\":(0,185),\"NO\":(0,350),\"NO2\":(0,175),\"NOx\":(0,400),\n",
        "           \"SO2\":(0,405),\"CO\":(0,10),\"RH\":(0,100),\"WS\":(0,40),\"TEMP\":(-4.5,45),\"SR\":(0,1.2),\n",
        "           \"BP\":(688,740),\"WD\":(0,360),\"RAINF\":(0,25)}\n",
        "}\n",
        "\n",
        "# =========================================\n",
        "# 2) Utilidades\n",
        "# =========================================\n",
        "\n",
        "def try_parse_datetime(x):\n",
        "    if pd.isna(x):\n",
        "        return pd.NaT\n",
        "    if isinstance(x, pd.Timestamp):\n",
        "        return x\n",
        "    try:\n",
        "        return pd.to_datetime(x, errors=\"coerce\")\n",
        "    except Exception:\n",
        "        try:\n",
        "            return pd.to_datetime(dtparser.parse(str(x)), errors=\"coerce\")\n",
        "        except Exception:\n",
        "            return pd.NaT\n",
        "\n",
        "def coerce_numeric(series: pd.Series) -> pd.Series:\n",
        "    \"\"\"Convierte strings '1,234.5' o '1.234,5' y otros a float; deja NaN si no se puede.\"\"\"\n",
        "    s = series.astype(str).str.replace(r\"[^\\d\\-\\.,]\", \"\", regex=True).str.strip()\n",
        "    # Si hay comas y puntos: asume 1,234.56 (inglés) → quita comas\n",
        "    s = pd.Series(np.where(s.str.contains(\",\") & s.str.contains(r\"\\.\"), s.str.replace(\",\", \"\", regex=False), s))\n",
        "    # Si hay comas pero no puntos: asume decimal con coma (1.234,56 → 1234.56)\n",
        "    s = pd.Series(np.where((~pd.isna(s)) & (pd.Series(s).str.contains(\",\") & ~pd.Series(s).str.contains(r\"\\.\")),\n",
        "                 pd.Series(s).str.replace(\".\", \"\", regex=False).str.replace(\",\", \".\", regex=False),\n",
        "                 s))\n",
        "    out = pd.to_numeric(pd.Series(s), errors=\"coerce\")\n",
        "    return out\n",
        "\n",
        "def standardize_column_names(cols: List[str]) -> List[str]:\n",
        "    \"\"\"Normaliza nombres típicos para mapear a EXPECTED_COLS.\"\"\"\n",
        "    mapping = {\n",
        "        r\"^pm\\s*10$\":\"PM10\",\n",
        "        r\"^pm10$\":\"PM10\",\n",
        "        r\"^pm\\s*2\\.?5$\":\"PM2.5\",\n",
        "        r\"^pm2\\.?5$\":\"PM2.5\",\n",
        "        r\"^o3$\":\"O3\",\n",
        "        r\"^no$\":\"NO\",\n",
        "        r\"^no2$\":\"NO2\",\n",
        "        r\"^nox$\":\"NOx\",\n",
        "        r\"^so2$\":\"SO2\",\n",
        "        r\"^co$\":\"CO\",\n",
        "        r\"^rh$\":\"RH\",\n",
        "        r\"^ws$\":\"WS\",\n",
        "        r\"^(temp|temperature)$\":\"TEMP\",\n",
        "        r\"^sr$\":\"SR\",\n",
        "        r\"^bp$\":\"BP\",\n",
        "        r\"^wd$\":\"WD\",\n",
        "        r\"^(rain|rainf|rainfall|precip.*)$\":\"RAINF\",\n",
        "        r\"^(date|datetime|fecha.*hora|fecha_hora|time.*)$\":TIME_COL,\n",
        "        r\"^(estacion|estación|station)$\":\"STATION\",\n",
        "    }\n",
        "    new_cols = []\n",
        "    for c in cols:\n",
        "        c0 = str(c).strip()\n",
        "        c1 = re.sub(r\"\\s+\", \" \", c0)\n",
        "        c2 = c1.upper()\n",
        "        new = c2\n",
        "        for pat, tgt in mapping.items():\n",
        "            if re.match(pat, c2, flags=re.IGNORECASE):\n",
        "                new = tgt\n",
        "                break\n",
        "        new_cols.append(new)\n",
        "    return new_cols\n",
        "\n",
        "def add_station_if_missing(df: pd.DataFrame, station_name: str) -> pd.DataFrame:\n",
        "    if \"STATION\" not in df.columns:\n",
        "        df[\"STATION\"] = station_name\n",
        "    return df\n",
        "\n",
        "def concat_sheets_with_station(reader, sheet_names):\n",
        "    dfs = []\n",
        "    for sh in sheet_names:\n",
        "        try:\n",
        "            df = reader.parse(sh)\n",
        "        except Exception:\n",
        "            df = reader.parse(sh, header=0)\n",
        "        df.columns = standardize_column_names(list(df.columns))\n",
        "        df = add_station_if_missing(df, sh)\n",
        "        dfs.append(df)\n",
        "    return pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "def read_numbers_as_dataframe(path_numbers: str) -> pd.DataFrame:\n",
        "    \"\"\"Lee un archivo .numbers como tablas y concatena.\"\"\"\n",
        "    try:\n",
        "        from numbers_parser import Document\n",
        "    except ImportError as e:\n",
        "        raise RuntimeError(\"Falta instalar 'numbers-parser'. Ejecuta: !pip install numbers-parser\") from e\n",
        "\n",
        "    doc = Document(path_numbers)\n",
        "    frames = []\n",
        "    for sheet in doc.sheets:\n",
        "        for table in sheet.tables:\n",
        "            data = table.rows(values_only=True)\n",
        "            if not data:\n",
        "                continue\n",
        "            df = pd.DataFrame(data[1:], columns=data[0]) if len(data) > 1 else pd.DataFrame(columns=data[0])\n",
        "            df.columns = standardize_column_names(df.columns.tolist())\n",
        "            df = add_station_if_missing(df, sheet.name)\n",
        "            frames.append(df)\n",
        "    if not frames:\n",
        "        return pd.DataFrame(columns=[TIME_COL, \"STATION\"] + EXPECTED_COLS)\n",
        "    return pd.concat(frames, ignore_index=True)\n",
        "\n",
        "def read_data() -> pd.DataFrame:\n",
        "    if READ_NUMBERS and os.path.exists(PATH_DATA_NUMBERS):\n",
        "        df = read_numbers_as_dataframe(PATH_DATA_NUMBERS)\n",
        "    elif os.path.exists(PATH_DATA_XLSX):\n",
        "        xls = pd.ExcelFile(PATH_DATA_XLSX)\n",
        "        df = concat_sheets_with_station(xls, xls.sheet_names)\n",
        "    else:\n",
        "        raise FileNotFoundError(\"No se encontró el archivo .numbers ni el .xlsx. Sube uno de los dos con el nombre esperado.\")\n",
        "    # Normaliza nombres y asegura columnas esperadas\n",
        "    df.columns = standardize_column_names(df.columns.tolist())\n",
        "    for c in EXPECTED_COLS:\n",
        "        if c not in df.columns:\n",
        "            df[c] = np.nan\n",
        "    if TIME_COL in df.columns:\n",
        "        df[TIME_COL] = df[TIME_COL].apply(try_parse_datetime)\n",
        "    return df\n",
        "\n",
        "def read_etiquetas():\n",
        "    \"\"\"Lee un diccionario de etiquetas si existe; si no, retorna None.\"\"\"\n",
        "    if not os.path.exists(PATH_ETIQUETAS):\n",
        "        return None\n",
        "    try:\n",
        "        et = pd.read_excel(PATH_ETIQUETAS)\n",
        "        return et\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# =========================================\n",
        "# 3) 1) Comprensión de los datos (versión robusta)\n",
        "# =========================================\n",
        "\n",
        "def describe_variables(df: pd.DataFrame, etiquetas: pd.DataFrame | None) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Devuelve un dataframe con:\n",
        "        nombre, descripcion, tipo, valores_posibles, nulos\n",
        "    Soporta numéricas, categóricas, booleanas y fecha/hora.\n",
        "    \"\"\"\n",
        "    summary = []\n",
        "    for c in df.columns:\n",
        "        ser = df[c]\n",
        "        n_null = int(ser.isna().sum())\n",
        "\n",
        "        if is_datetime64_any_dtype(ser):\n",
        "            tipo = \"Fecha/Hora\"\n",
        "            if ser.notna().any():\n",
        "                vmin = pd.to_datetime(ser.min())\n",
        "                vmax = pd.to_datetime(ser.max())\n",
        "                vals = [vmin.isoformat(), vmax.isoformat()]\n",
        "            else:\n",
        "                vals = [np.nan, np.nan]\n",
        "\n",
        "        elif is_bool_dtype(ser):\n",
        "            tipo = \"Categórico (bool)\"\n",
        "            uniq = ser.dropna().unique().tolist()\n",
        "            vals = uniq[:20] + ([\"...\"] if len(uniq) > 20 else [])\n",
        "\n",
        "        elif is_categorical_dtype(ser) or ser.dtype == \"object\":\n",
        "            tipo = \"Categórico\"\n",
        "            uniq = ser.dropna().unique().tolist()\n",
        "            vals = uniq[:20] + ([\"...\"] if len(uniq) > 20 else [])\n",
        "\n",
        "        elif is_numeric_dtype(ser):\n",
        "            tipo = \"Numérico\"\n",
        "            if ser.notna().any():\n",
        "                vmin = np.nanmin(ser.astype(float))\n",
        "                vmax = np.nanmax(ser.astype(float))\n",
        "                vals = [float(vmin), float(vmax)]\n",
        "            else:\n",
        "                vals = [np.nan, np.nan]\n",
        "\n",
        "        else:\n",
        "            tipo = str(ser.dtype)\n",
        "            uniq = ser.dropna().unique().tolist()\n",
        "            vals = uniq[:20] + ([\"...\"] if len(uniq) > 20 else [])\n",
        "\n",
        "        summary.append({\n",
        "            \"variable\": c,\n",
        "            \"descripcion\": None,\n",
        "            \"tipo\": tipo,\n",
        "            \"valores_posibles\": vals,\n",
        "            \"nulos\": n_null\n",
        "        })\n",
        "\n",
        "    desc_df = pd.DataFrame(summary)\n",
        "\n",
        "    # Integración opcional con Etiquetas.xlsx\n",
        "    if etiquetas is not None:\n",
        "        et = etiquetas.copy()\n",
        "        if \"variable\" not in et.columns:\n",
        "            cand = [col for col in et.columns if \"var\" in col.lower() or \"nombre\" in col.lower()]\n",
        "            if cand:\n",
        "                et = et.rename(columns={cand[0]: \"variable\"})\n",
        "        for candidate, target in [\n",
        "            (\"descripcion\",\"descripcion\"),\n",
        "            (\"descripción\",\"descripcion\"),\n",
        "            (\"tipo\",\"tipo_usuario\"),\n",
        "            (\"valores\",\"valores_usuario\"),\n",
        "            (\"valores_posibles\",\"valores_usuario\")\n",
        "        ]:\n",
        "            if candidate in et.columns and target not in et.columns:\n",
        "                et = et.rename(columns={candidate: target})\n",
        "        if \"variable\" in et.columns:\n",
        "            desc_df = desc_df.merge(et, on=\"variable\", how=\"left\")\n",
        "            if \"tipo_usuario\" in desc_df.columns:\n",
        "                desc_df[\"tipo\"] = desc_df[\"tipo_usuario\"].fillna(desc_df[\"tipo\"])\n",
        "            if \"valores_usuario\" in desc_df.columns:\n",
        "                desc_df[\"valores_posibles\"] = desc_df[\"valores_usuario\"].combine_first(desc_df[\"valores_posibles\"])\n",
        "            for col in [\"tipo_usuario\", \"valores_usuario\"]:\n",
        "                if col in desc_df.columns:\n",
        "                    desc_df.drop(columns=[col], inplace=True)\n",
        "\n",
        "    return desc_df\n",
        "\n",
        "def quality_checks(df: pd.DataFrame) -> dict:\n",
        "    qc = {}\n",
        "    qc[\"shape\"] = df.shape\n",
        "    qc[\"missing_by_col\"] = df.isna().sum().sort_values(ascending=False).to_dict()\n",
        "    qc[\"has_infinite\"] = np.isinf(df.select_dtypes(include=[np.number]).to_numpy()).any()\n",
        "    qc[\"duplicated_rows\"] = int(df.duplicated().sum())\n",
        "    return qc\n",
        "\n",
        "# =========================================\n",
        "# 4) 2) Preparación de los datos\n",
        "# =========================================\n",
        "\n",
        "def select_and_explain(df: pd.DataFrame) -> Tuple[pd.DataFrame, str]:\n",
        "    \"\"\"Selecciona columnas de tiempo, estación y variables estándar.\"\"\"\n",
        "    keep = [TIME_COL, \"STATION\"] + EXPECTED_COLS\n",
        "    keep = [c for c in keep if c in df.columns]\n",
        "    out = df[keep].copy()\n",
        "    explanation = (\n",
        "        \"Se seleccionaron las columnas de tiempo (DATETIME), STATION y variables de medición estándar. \"\n",
        "        \"Se excluyeron columnas auxiliares para evitar ruido y garantizar comparabilidad.\"\n",
        "    )\n",
        "    return out, explanation\n",
        "\n",
        "def identify_targets(df: pd.DataFrame) -> List[str]:\n",
        "    \"\"\"Columnas objetivo sugeridas (ajústalo a tu análisis).\"\"\"\n",
        "    return [c for c in [\"PM2.5\",\"PM10\"] if c in df.columns]\n",
        "\n",
        "def fix_types(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Convierte mediciones a numérico\n",
        "    for c in EXPECTED_COLS:\n",
        "        if c in df.columns:\n",
        "            df[c] = coerce_numeric(df[c])\n",
        "    # Asegura datetime y variables derivadas de tiempo\n",
        "    if TIME_COL in df.columns:\n",
        "        if not is_datetime64_any_dtype(df[TIME_COL]):\n",
        "            df[TIME_COL] = pd.to_datetime(df[TIME_COL], errors=\"coerce\")\n",
        "        df[\"YEAR\"] = df[TIME_COL].dt.year\n",
        "        df[\"MONTH\"] = df[TIME_COL].dt.month\n",
        "        df[\"DAY\"] = df[TIME_COL].dt.day\n",
        "        df[\"HOUR\"] = df[TIME_COL].dt.hour\n",
        "    return df\n",
        "\n",
        "def apply_yearly_ranges(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Marca como NaN los valores fuera de rango conforme al año de la fila.\"\"\"\n",
        "    if \"YEAR\" not in df.columns:\n",
        "        return df\n",
        "    def clip_row(row):\n",
        "        yr = row[\"YEAR\"]\n",
        "        ranges = RANGOS_POR_ANIO.get(int(yr) if not pd.isna(yr) else yr, {})\n",
        "        for col, (lo, hi) in ranges.items():\n",
        "            if col in row and pd.notna(row[col]):\n",
        "                v = row[col]\n",
        "                if (v < lo) or (v > hi):\n",
        "                    row[col] = np.nan\n",
        "        return row\n",
        "    return df.apply(clip_row, axis=1)\n",
        "\n",
        "def drop_duplicates(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    before = len(df)\n",
        "    df = df.drop_duplicates()\n",
        "    after = len(df)\n",
        "    print(f\"Duplicados eliminados (filas exactas): {before - after}\")\n",
        "    if TIME_COL in df.columns and \"STATION\" in df.columns:\n",
        "        before = len(df)\n",
        "        df = df.sort_values(by=[TIME_COL]).drop_duplicates(subset=[\"STATION\", TIME_COL], keep=\"first\")\n",
        "        after = len(df)\n",
        "        print(f\"Duplicados por clave (STATION, DATETIME): {before - after}\")\n",
        "    return df\n",
        "\n",
        "def handle_missing(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Manejo de NA:\n",
        "      - Interpolación temporal por estación para series numéricas (con índice de tiempo).\n",
        "      - ffill/bfill cortos.\n",
        "      - Imputación global opcional (media/mediana).\n",
        "    \"\"\"\n",
        "    num_cols = [c for c in df.columns if c in EXPECTED_COLS]\n",
        "    if TIME_COL in df.columns and \"STATION\" in df.columns:\n",
        "        # Operar por estación con índice de tiempo para usar method=\"time\"\n",
        "        def _interpolate_group(g):\n",
        "            g = g.sort_values(TIME_COL)\n",
        "            g_idx = g.set_index(TIME_COL)\n",
        "            for c in num_cols:\n",
        "                s = g_idx[c]\n",
        "                s = s.interpolate(method=\"time\")\n",
        "                s = s.ffill().bfill()\n",
        "                g_idx[c] = s\n",
        "            return g_idx.reset_index()\n",
        "        df = df.groupby(\"STATION\", group_keys=False).apply(_interpolate_group)\n",
        "\n",
        "    if IMPUTE_STRATEGY in (\"mean\",\"median\"):\n",
        "        imputer = SimpleImputer(strategy=IMPUTE_STRATEGY)\n",
        "        df[num_cols] = imputer.fit_transform(df[num_cols])\n",
        "\n",
        "    return df\n",
        "\n",
        "def handle_categoricals(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    cat_cols = [c for c in df.columns if df[c].dtype == \"object\" or str(df[c].dtype).startswith(\"category\")]\n",
        "    if CREATE_DUMMIES and cat_cols:\n",
        "        df = pd.get_dummies(df, columns=cat_cols, drop_first=True, dtype=int)\n",
        "    return df\n",
        "\n",
        "def iqr_outlier_mask(x: pd.Series, k: float = 1.5):\n",
        "    q1, q3 = np.nanpercentile(x, [25, 75])\n",
        "    iqr = q3 - q1\n",
        "    lo, hi = q1 - k*iqr, q3 + k*iqr\n",
        "    return (x < lo) | (x > hi)\n",
        "\n",
        "def handle_outliers(df: pd.DataFrame, k: float = 1.5) -> pd.DataFrame:\n",
        "    \"\"\"Manejo de atípicos (IQR) por estación y año. Se marcan como NaN.\"\"\"\n",
        "    if \"STATION\" not in df.columns or \"YEAR\" not in df.columns:\n",
        "        return df\n",
        "    num_cols = [c for c in EXPECTED_COLS if c in df.columns]\n",
        "    def _proc(group):\n",
        "        for c in num_cols:\n",
        "            s = group[c]\n",
        "            if s.notna().sum() >= 12:\n",
        "                mask = iqr_outlier_mask(s, k=k)\n",
        "                group.loc[mask, c] = np.nan\n",
        "        return group\n",
        "    return df.groupby([\"STATION\",\"YEAR\"], group_keys=False).apply(_proc)\n",
        "\n",
        "# =========================================\n",
        "# 5) 3) Transformación de Datos\n",
        "# =========================================\n",
        "\n",
        "def build_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Atributos derivados: componentes del viento y variables de calendario.\"\"\"\n",
        "    out = df.copy()\n",
        "    if \"WS\" in out.columns and \"WD\" in out.columns:\n",
        "        ws = out[\"WS\"].astype(float)\n",
        "        wd_rad = np.deg2rad(out[\"WD\"].astype(float))\n",
        "        out[\"WIND_U\"] = -ws * np.sin(wd_rad)\n",
        "        out[\"WIND_V\"] = -ws * np.cos(wd_rad)\n",
        "    if TIME_COL in out.columns:\n",
        "        out[\"WEEKDAY\"] = out[TIME_COL].dt.weekday  # 0=lun\n",
        "        out[\"IS_WEEKEND\"] = (out[\"WEEKDAY\"] >= 5).astype(int)\n",
        "    return out\n",
        "\n",
        "def scale_numeric(df: pd.DataFrame) -> Tuple[pd.DataFrame, dict]:\n",
        "    if SCALING not in (\"standard\",\"minmax\"):\n",
        "        return df, {}\n",
        "    num_cols = [c for c in df.columns if c in EXPECTED_COLS or c in [\"WIND_U\",\"WIND_V\"]]\n",
        "    num_cols = [c for c in num_cols if c in df.columns]\n",
        "    scaler = StandardScaler() if SCALING==\"standard\" else MinMaxScaler()\n",
        "    scaled = df.copy()\n",
        "    scaled[num_cols] = scaler.fit_transform(scaled[num_cols])\n",
        "    info = {\"scaler\": SCALING, \"columns\": num_cols}\n",
        "    return scaled, info\n",
        "\n",
        "def bin_numeric(df: pd.DataFrame, cols: List[str]) -> Tuple[pd.DataFrame, dict]:\n",
        "    if BINNING not in (\"quantile\",\"uniform\") or not cols:\n",
        "        return df, {}\n",
        "    binner = KBinsDiscretizer(n_bins=N_BINS, encode=\"ordinal\",\n",
        "                              strategy=(\"quantile\" if BINNING==\"quantile\" else \"uniform\"))\n",
        "    x = df[cols].copy()\n",
        "    mask = x.notna().all(axis=1)\n",
        "    x_notna = x[mask]\n",
        "    out = df.copy()\n",
        "    out.loc[mask, [f\"{c}_BIN\" for c in cols]] = binner.fit_transform(x_notna)\n",
        "    info = {\"binner\": BINNING, \"columns\": cols, \"bins\": N_BINS}\n",
        "    return out, info\n",
        "\n",
        "# =========================================\n",
        "# 6) 4) Reformateo / Exportación\n",
        "# =========================================\n",
        "\n",
        "def tidy_and_export(df: pd.DataFrame, outdir=\"/content/clean\"):\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    # Exporta completo\n",
        "    full_path = os.path.join(outdir, \"air_quality_clean_full.parquet\")\n",
        "    df.to_parquet(full_path, index=False)\n",
        "    print(f\"✅ Exportado dataset completo: {full_path}\")\n",
        "\n",
        "    # Por año\n",
        "    if \"YEAR\" in df.columns:\n",
        "        for yr, dfg in df.groupby(\"YEAR\"):\n",
        "            p = os.path.join(outdir, f\"air_quality_clean_{int(yr)}.csv\")\n",
        "            dfg.to_csv(p, index=False)\n",
        "    # Por estación y año\n",
        "    if \"STATION\" in df.columns and \"YEAR\" in df.columns:\n",
        "        for (st, yr), dfg in df.groupby([\"STATION\",\"YEAR\"]):\n",
        "            fname = re.sub(r\"[^A-Za-z0-9\\-]+\",\"_\", str(st))\n",
        "            p = os.path.join(outdir, f\"clean_{fname}_{int(yr)}.csv\")\n",
        "            dfg.to_csv(p, index=False)\n",
        "    print(\"📦 Exportaciones por año y por estación listas en:\", outdir)\n",
        "\n",
        "# =========================================\n",
        "# 7) RUN: pipeline maestro\n",
        "# =========================================\n",
        "\n",
        "def main():\n",
        "    print(\"=== Cargando datos ===\")\n",
        "    df = read_data()\n",
        "    print(\"Dimensión inicial:\", df.shape)\n",
        "\n",
        "    # -------- Comprensión de datos --------\n",
        "    print(\"\\n=== 1) Comprensión de los datos ===\")\n",
        "    etiquetas = read_etiquetas()\n",
        "    desc = describe_variables(df, etiquetas)\n",
        "    print(\"Dimensión del dataset:\", df.shape)\n",
        "    print(\"\\nDiccionario de variables (primeras filas):\")\n",
        "    display(desc.head(30))\n",
        "\n",
        "    qc = quality_checks(df)\n",
        "    print(\"\\nCalidad de datos:\")\n",
        "    print(\" - Registros, Columnas:\", qc[\"shape\"])\n",
        "    print(\" - Faltantes por columna (top 10):\", dict(list(qc[\"missing_by_col\"].items())[:10]))\n",
        "    print(\" - Valores infinitos:\", qc[\"has_infinite\"])\n",
        "    print(\" - Filas duplicadas totales:\", qc[\"duplicated_rows\"])\n",
        "\n",
        "    # -------- Preparación --------\n",
        "    print(\"\\n=== 2) Preparación de los datos ===\")\n",
        "    df, rationale = select_and_explain(df)\n",
        "    print(\"Racional de selección:\\n\", rationale)\n",
        "\n",
        "    df = fix_types(df)                # tipos + YEAR/MONTH/DAY/HOUR\n",
        "    df = apply_yearly_ranges(df)      # rangos por año del PDF\n",
        "    df = drop_duplicates(df)          # duplicados\n",
        "    df = handle_outliers(df, k=1.5)   # outliers → NaN\n",
        "    df = handle_missing(df)           # interpolación por estación + ffill/bfill + imputación opcional\n",
        "\n",
        "    targets = identify_targets(df)\n",
        "    print(\"Columnas objetivo sugeridas:\", targets)\n",
        "\n",
        "    df = handle_categoricals(df)      # dummies para categóricas (si aplica)\n",
        "\n",
        "    # -------- Transformación --------\n",
        "    print(\"\\n=== 3) Transformación de Datos ===\")\n",
        "    df = build_features(df)\n",
        "\n",
        "    df_scaled, scale_info = scale_numeric(df)\n",
        "    if scale_info:\n",
        "        print(\"Escalado aplicado:\", scale_info)\n",
        "\n",
        "    bin_cols = [c for c in [\"PM2.5\",\"PM10\"] if c in df_scaled.columns]\n",
        "    df_binned, bin_info = bin_numeric(df_scaled, bin_cols)\n",
        "    if bin_info:\n",
        "        print(\"Binning aplicado:\", bin_info)\n",
        "\n",
        "    # -------- Reformateo / Exportación --------\n",
        "    print(\"\\n=== 4) Reformateo / Exportación ===\")\n",
        "    tidy_and_export(df_binned)\n",
        "\n",
        "    # Reporte final breve\n",
        "    print(\"\\n=== Resumen RÁPIDO ===\")\n",
        "    print(\"Filas/Columnas finales:\", df_binned.shape)\n",
        "    print(\"NA totales:\", int(df_binned.isna().sum().sum()))\n",
        "    print(\"Columnas creadas (derivadas):\", [c for c in [\"WIND_U\",\"WIND_V\",\"WEEKDAY\",\"IS_WEEKEND\"] if c in df_binned.columns])\n",
        "    print(\"Listo ✅\")\n",
        "\n",
        "# Ejecutar\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "czQITkg9UGcU",
        "outputId": "dda63ae8-5992-4933-f1da-c36f6f0814d0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Cargando datos ===\n",
            "Dimensión inicial: (13883, 260)\n",
            "\n",
            "=== 1) Comprensión de los datos ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1828814518.py:248: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  elif is_categorical_dtype(ser) or ser.dtype == \"object\":\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensión del dataset: (13883, 260)\n",
            "\n",
            "Diccionario de variables (primeras filas):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       variable descripcion        tipo  \\\n",
              "0    UNNAMED: 0        None    Numérico   \n",
              "1    UNNAMED: 1        None  Categórico   \n",
              "2    UNNAMED: 2        None  Categórico   \n",
              "3    UNNAMED: 3        None  Categórico   \n",
              "4       STATION        None  Categórico   \n",
              "5      DATETIME        None  Fecha/Hora   \n",
              "6       SURESTE        None  Categórico   \n",
              "7     SURESTE.1        None  Categórico   \n",
              "8     SURESTE.2        None  Categórico   \n",
              "9     SURESTE.3        None  Categórico   \n",
              "10    SURESTE.4        None  Categórico   \n",
              "11    SURESTE.5        None  Categórico   \n",
              "12    SURESTE.6        None  Categórico   \n",
              "13    SURESTE.7        None  Categórico   \n",
              "14    SURESTE.8        None  Categórico   \n",
              "15    SURESTE.9        None  Categórico   \n",
              "16   SURESTE.10        None  Categórico   \n",
              "17   SURESTE.11        None  Categórico   \n",
              "18   SURESTE.12        None  Categórico   \n",
              "19   SURESTE.13        None  Categórico   \n",
              "20   SURESTE.14        None  Categórico   \n",
              "21  UNNAMED: 16        None    Numérico   \n",
              "22      NORESTE        None  Categórico   \n",
              "23    NORESTE.1        None  Categórico   \n",
              "24    NORESTE.2        None  Categórico   \n",
              "25    NORESTE.3        None  Categórico   \n",
              "26    NORESTE.4        None  Categórico   \n",
              "27    NORESTE.5        None  Categórico   \n",
              "28    NORESTE.6        None  Categórico   \n",
              "29    NORESTE.7        None  Categórico   \n",
              "\n",
              "                                     valores_posibles  nulos  \n",
              "0                                          [nan, nan]  13883  \n",
              "1   [This document was exported from Numbers.  Eac...  13879  \n",
              "2                       [Numbers Table Name, Table 1]  13880  \n",
              "3   [Excel Worksheet Name, Param_horarios_Estacion...  13880  \n",
              "4         [Export Summary, Param_horarios_Estaciones]      0  \n",
              "5          [2023-01-01T00:00:00, 2024-07-31T23:00:00]     13  \n",
              "6   [CO, ppm, 2.37, 2.12, 2.05, 2.5, 1.94, 1.35, 1...    196  \n",
              "7   [NO, ppb, 54.5, 38.7, 60.5, 42.3, 10.2, 7.8, 5...    377  \n",
              "8   [NO2, ppb, 32.6, 30.3, 28.8, 29.1, 25.7, 23.1,...    164  \n",
              "9   [NOX, ppb, 87.1, 68.9, 67.4, 89.4, 67.7, 33.2,...    165  \n",
              "10  [O3, ppb, 3, 4, 10, 13, 16, 17, 24, 31, 53, 54...    417  \n",
              "11  [PM10, ug/m3, 110, 116, 117, 135, 132, 96, 59,...    393  \n",
              "12  [PM2.5, ug/m3, 68, 67.18, 75.12, 82.81, 59.56,...   3693  \n",
              "13  [PRS, mmhg, 721.7, 721.5, 721.1, 720.8, 720.7,...    141  \n",
              "14  [RAINF, mm/hr, 0, 0.02, 0.04, 0.03, 0.01, 0.74...    143  \n",
              "15  [RH, %, 68, 72, 71, 73, 59, 51, 39, 37, 28, 24...    176  \n",
              "16  [SO2, ppb, 3.5, 3.4, 3.6, 3.8, 3, 3.3, 3.2, 5....    233  \n",
              "17  [SR, KW/m2, 0, 0.006, 0.089, 0.229, 0.328, 0.3...     70  \n",
              "18  [TOUT, degC, 16.39, 15.17, 14.82, 15.51, 13.81...    138  \n",
              "19  [WSR, KMPH, 3.2, 3.3, 3.7, 3.6, 4.9, 6.8, 8.4,...    139  \n",
              "20  [WDV, DEG, 257, 278, 197, 271, 284, 286, 287, ...    141  \n",
              "21                                         [nan, nan]  13883  \n",
              "22  [CO, ppm, 3.4, 4.3, 4.28, 3.77, 2.98, 2.1, 3.0...    599  \n",
              "23  [NO, ppb, 30.4, 67.2, 63.9, 57.2, 41.9, 16.5, ...    299  \n",
              "24  [NO2, ppb, 43, 44.4, 41.5, 42.3, 39.9, 35.1, 3...    227  \n",
              "25  [NOX, ppb, 73.4, 111.6, 105.5, 99.5, 81.8, 51....    229  \n",
              "26  [O3, ppb, 7, 8, 6, 5, 4, 11, 21, 34, 43, 47, 5...    683  \n",
              "27  [PM10, ug/m3, 222, 311, 723, 473, 372, 285, 17...    447  \n",
              "28  [PM2.5, ug/m3, 400, 349, 260, 157, 195, 90, 11...   1567  \n",
              "29  [PRS, mmhg, 718.4, 718.1, 717.8, 717.6, 718, 7...    254  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32d5e39a-1f13-4895-b07c-751118bd62e1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>variable</th>\n",
              "      <th>descripcion</th>\n",
              "      <th>tipo</th>\n",
              "      <th>valores_posibles</th>\n",
              "      <th>nulos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>UNNAMED: 0</td>\n",
              "      <td>None</td>\n",
              "      <td>Numérico</td>\n",
              "      <td>[nan, nan]</td>\n",
              "      <td>13883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>UNNAMED: 1</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[This document was exported from Numbers.  Eac...</td>\n",
              "      <td>13879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>UNNAMED: 2</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[Numbers Table Name, Table 1]</td>\n",
              "      <td>13880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>UNNAMED: 3</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[Excel Worksheet Name, Param_horarios_Estacion...</td>\n",
              "      <td>13880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>STATION</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[Export Summary, Param_horarios_Estaciones]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>DATETIME</td>\n",
              "      <td>None</td>\n",
              "      <td>Fecha/Hora</td>\n",
              "      <td>[2023-01-01T00:00:00, 2024-07-31T23:00:00]</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SURESTE</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[CO, ppm, 2.37, 2.12, 2.05, 2.5, 1.94, 1.35, 1...</td>\n",
              "      <td>196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SURESTE.1</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[NO, ppb, 54.5, 38.7, 60.5, 42.3, 10.2, 7.8, 5...</td>\n",
              "      <td>377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SURESTE.2</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[NO2, ppb, 32.6, 30.3, 28.8, 29.1, 25.7, 23.1,...</td>\n",
              "      <td>164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SURESTE.3</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[NOX, ppb, 87.1, 68.9, 67.4, 89.4, 67.7, 33.2,...</td>\n",
              "      <td>165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>SURESTE.4</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[O3, ppb, 3, 4, 10, 13, 16, 17, 24, 31, 53, 54...</td>\n",
              "      <td>417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>SURESTE.5</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[PM10, ug/m3, 110, 116, 117, 135, 132, 96, 59,...</td>\n",
              "      <td>393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>SURESTE.6</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[PM2.5, ug/m3, 68, 67.18, 75.12, 82.81, 59.56,...</td>\n",
              "      <td>3693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>SURESTE.7</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[PRS, mmhg, 721.7, 721.5, 721.1, 720.8, 720.7,...</td>\n",
              "      <td>141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>SURESTE.8</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[RAINF, mm/hr, 0, 0.02, 0.04, 0.03, 0.01, 0.74...</td>\n",
              "      <td>143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>SURESTE.9</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[RH, %, 68, 72, 71, 73, 59, 51, 39, 37, 28, 24...</td>\n",
              "      <td>176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>SURESTE.10</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[SO2, ppb, 3.5, 3.4, 3.6, 3.8, 3, 3.3, 3.2, 5....</td>\n",
              "      <td>233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>SURESTE.11</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[SR, KW/m2, 0, 0.006, 0.089, 0.229, 0.328, 0.3...</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>SURESTE.12</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[TOUT, degC, 16.39, 15.17, 14.82, 15.51, 13.81...</td>\n",
              "      <td>138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>SURESTE.13</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[WSR, KMPH, 3.2, 3.3, 3.7, 3.6, 4.9, 6.8, 8.4,...</td>\n",
              "      <td>139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>SURESTE.14</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[WDV, DEG, 257, 278, 197, 271, 284, 286, 287, ...</td>\n",
              "      <td>141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>UNNAMED: 16</td>\n",
              "      <td>None</td>\n",
              "      <td>Numérico</td>\n",
              "      <td>[nan, nan]</td>\n",
              "      <td>13883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>NORESTE</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[CO, ppm, 3.4, 4.3, 4.28, 3.77, 2.98, 2.1, 3.0...</td>\n",
              "      <td>599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>NORESTE.1</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[NO, ppb, 30.4, 67.2, 63.9, 57.2, 41.9, 16.5, ...</td>\n",
              "      <td>299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>NORESTE.2</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[NO2, ppb, 43, 44.4, 41.5, 42.3, 39.9, 35.1, 3...</td>\n",
              "      <td>227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>NORESTE.3</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[NOX, ppb, 73.4, 111.6, 105.5, 99.5, 81.8, 51....</td>\n",
              "      <td>229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>NORESTE.4</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[O3, ppb, 7, 8, 6, 5, 4, 11, 21, 34, 43, 47, 5...</td>\n",
              "      <td>683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>NORESTE.5</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[PM10, ug/m3, 222, 311, 723, 473, 372, 285, 17...</td>\n",
              "      <td>447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>NORESTE.6</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[PM2.5, ug/m3, 400, 349, 260, 157, 195, 90, 11...</td>\n",
              "      <td>1567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>NORESTE.7</td>\n",
              "      <td>None</td>\n",
              "      <td>Categórico</td>\n",
              "      <td>[PRS, mmhg, 718.4, 718.1, 717.8, 717.6, 718, 7...</td>\n",
              "      <td>254</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32d5e39a-1f13-4895-b07c-751118bd62e1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-32d5e39a-1f13-4895-b07c-751118bd62e1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-32d5e39a-1f13-4895-b07c-751118bd62e1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4fc7727d-02f4-4c32-b0c7-2328dc5fbf08\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4fc7727d-02f4-4c32-b0c7-2328dc5fbf08')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4fc7727d-02f4-4c32-b0c7-2328dc5fbf08 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Calidad de datos:\n",
            " - Registros, Columnas: (13883, 260)\n",
            " - Faltantes por columna (top 10): {'RAINF': 13883, 'UNNAMED: 0': 13883, 'UNNAMED: 224': 13883, 'UNNAMED: 16': 13883, 'UNNAMED: 208': 13883, 'UNNAMED: 32': 13883, 'UNNAMED: 192': 13883, 'O3': 13883, 'SO2': 13883, 'UNNAMED: 112': 13883}\n",
            " - Valores infinitos: False\n",
            " - Filas duplicadas totales: 4\n",
            "\n",
            "=== 2) Preparación de los datos ===\n",
            "Racional de selección:\n",
            " Se seleccionaron las columnas de tiempo (DATETIME), STATION y variables de medición estándar. Se excluyeron columnas auxiliares para evitar ruido y garantizar comparabilidad.\n",
            "Duplicados eliminados (filas exactas): 11\n",
            "Duplicados por clave (STATION, DATETIME): 0\n",
            "Columnas objetivo sugeridas: ['PM2.5', 'PM10']\n",
            "\n",
            "=== 3) Transformación de Datos ===\n",
            "Escalado aplicado: {'scaler': 'standard', 'columns': ['PM10', 'PM2.5', 'O3', 'NO', 'NO2', 'NOx', 'SO2', 'CO', 'RH', 'WS', 'TEMP', 'SR', 'BP', 'WD', 'RAINF', 'WIND_U', 'WIND_V']}\n",
            "\n",
            "=== 4) Reformateo / Exportación ===\n",
            "✅ Exportado dataset completo: /content/clean/air_quality_clean_full.parquet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1828814518.py:425: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return df.groupby([\"STATION\",\"YEAR\"], group_keys=False).apply(_proc)\n",
            "/tmp/ipython-input-1828814518.py:393: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df = df.groupby(\"STATION\", group_keys=False).apply(_interpolate_group)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 Exportaciones por año y por estación listas en: /content/clean\n",
            "\n",
            "=== Resumen RÁPIDO ===\n",
            "Filas/Columnas finales: (13870, 24)\n",
            "NA totales: 235790\n",
            "Columnas creadas (derivadas): ['WIND_U', 'WIND_V', 'WEEKDAY', 'IS_WEEKEND']\n",
            "Listo ✅\n"
          ]
        }
      ]
    }
  ]
}
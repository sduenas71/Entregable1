{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Limpieza y preparaci√≥n de datos de calidad del aire (Colab)\n",
        "# ============================================================\n",
        "# Requisitos (en una celda aparte si hace falta):\n",
        "# !pip install numbers-parser pandas numpy openpyxl xlrd scikit-learn pyjanitor python-dateutil\n",
        "\n",
        "import os\n",
        "import re\n",
        "import math\n",
        "import warnings\n",
        "from typing import Dict, Tuple, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from dateutil import parser as dtparser\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, KBinsDiscretizer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from IPython.display import display\n",
        "from pandas.api.types import (\n",
        "    is_numeric_dtype,\n",
        "    is_datetime64_any_dtype,\n",
        "    is_bool_dtype,\n",
        "    is_categorical_dtype,\n",
        ")\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# =========================================\n",
        "# 0) Par√°metros del usuario / rutas base\n",
        "# =========================================\n",
        "PATH_DATA_NUMBERS = \"/content/DATOS HISTORICOS 2023_2024_TODAS ESTACIONES_ITESM.numbers\"\n",
        "PATH_DATA_XLSX    = \"/content/DATOS HISTORICOS 2023_2024_TODAS ESTACIONES_ITESM.xlsx\"  # usando Excel\n",
        "PATH_ETIQUETAS    = \"/content/Etiquetas.xlsx\"\n",
        "\n",
        "# Si tu archivo est√° en .numbers, usa READ_NUMBERS=True. Si ya exportaste a .xlsx, pon False.\n",
        "READ_NUMBERS = False  # ‚Üê ahora que cambiaste a Excel\n",
        "\n",
        "# ¬øCrear variables dummy para categ√≥ricas?\n",
        "CREATE_DUMMIES = True\n",
        "\n",
        "# ¬øEstrategia de imputaci√≥n para NA al final del paso de limpieza?\n",
        "#   None            -> no imputar (se deja NaN tras interpolar y ffill/bfill)\n",
        "#   \"median\"        -> imputaci√≥n por mediana\n",
        "#   \"mean\"          -> imputaci√≥n por media\n",
        "IMPUTE_STRATEGY = None\n",
        "\n",
        "# ¬øEscalado de num√©ricas?\n",
        "#   None | \"standard\" | \"minmax\"\n",
        "SCALING = \"standard\"\n",
        "\n",
        "# ¬øBinning (discretizaci√≥n) de num√©ricas seleccionadas?\n",
        "#   None | \"quantile\" | \"uniform\"   (usa KBinsDiscretizer)\n",
        "BINNING = None\n",
        "N_BINS  = 5\n",
        "\n",
        "# Columnas esperadas de mediciones (nombres est√°ndar que forzaremos)\n",
        "EXPECTED_COLS = [\n",
        "    \"PM10\",\"PM2.5\",\"O3\",\"NO\",\"NO2\",\"NOx\",\"SO2\",\"CO\",\"RH\",\"WS\",\"TEMP\",\"SR\",\"BP\",\"WD\",\"RAINF\"\n",
        "]\n",
        "\n",
        "# Nombre de columna de tiempo\n",
        "TIME_COL = \"DATETIME\"\n",
        "\n",
        "# =========================================\n",
        "# 1) RANGOS por a√±o (del PDF)\n",
        "# =========================================\n",
        "RANGOS_POR_ANIO: Dict[int, Dict[str, Tuple[float, float]]] = {\n",
        "    2020: {\"PM10\":(0,800),\"PM2.5\":(0,205.94),\"O3\":(0,153),\"NO\":(0,500),\"NO2\":(0,200),\"NOx\":(0,500),\n",
        "           \"SO2\":(0,200),\"CO\":(0,20),\"RH\":(0,100),\"WS\":(0,75),\"TEMP\":(0,41),\"SR\":(0,1),\"BP\":(690,750),\n",
        "           \"WD\":(0,360),\"RAINF\":(0,30)},\n",
        "    2021: {\"PM10\":(0,800),\"PM2.5\":(0,325),\"O3\":(0,175),\"NO\":(0,350),\"NO2\":(0,100),\"NOx\":(0,400),\n",
        "           \"SO2\":(0,300),\"CO\":(0,10),\"RH\":(0,100),\"WS\":(0,40),\"TEMP\":(-6.5,45),\"SR\":(0,1),\n",
        "           \"BP\":(690,740),\"WD\":(0,360),\"RAINF\":(0,80)},\n",
        "    2022: {\"PM10\":(0,999),\"PM2.5\":(0,450),\"O3\":(0,160),\"NO\":(0,400),\"NO2\":(0,175),\"NOx\":(0,420),\n",
        "           \"SO2\":(0,200),\"CO\":(0,8),\"RH\":(0,100),\"WS\":(0,35),\"TEMP\":(-5,45),\"SR\":(0,1.25),\n",
        "           \"BP\":(700,740),\"WD\":(0,360),\"RAINF\":(0,25)},\n",
        "    2023: {\"PM10\":(0,900),\"PM2.5\":(0,800),\"O3\":(0,175),\"NO\":(0,500),\"NO2\":(0,175),\"NOx\":(0,500),\n",
        "           \"SO2\":(0,250),\"CO\":(0,14),\"RH\":(0,100),\"WS\":(0,40),\"TEMP\":(0,45),\"SR\":(0,1),\n",
        "           \"BP\":(690,740),\"WD\":(0,360),\"RAINF\":(0,70)},\n",
        "    2024: {\"PM10\":(0,999),\"PM2.5\":(0,999),\"O3\":(0,180),\"NO\":(0,400),\"NO2\":(0,130),\"NOx\":(0,500),\n",
        "           \"SO2\":(0,150),\"CO\":(0,18),\"RH\":(0,100),\"WS\":(0,38),\"TEMP\":(-4,45.5),\"SR\":(0,1.26),\n",
        "           \"BP\":(687.5,740),\"WD\":(0,360),\"RAINF\":(0,50)},\n",
        "    2025: {\"PM10\":(0,820),\"PM2.5\":(0,350),\"O3\":(0,185),\"NO\":(0,350),\"NO2\":(0,175),\"NOx\":(0,400),\n",
        "           \"SO2\":(0,405),\"CO\":(0,10),\"RH\":(0,100),\"WS\":(0,40),\"TEMP\":(-4.5,45),\"SR\":(0,1.2),\n",
        "           \"BP\":(688,740),\"WD\":(0,360),\"RAINF\":(0,25)}\n",
        "}\n",
        "\n",
        "# =========================================\n",
        "# 2) Utilidades\n",
        "# =========================================\n",
        "\n",
        "def try_parse_datetime(x):\n",
        "    if pd.isna(x):\n",
        "        return pd.NaT\n",
        "    if isinstance(x, pd.Timestamp):\n",
        "        return x\n",
        "    try:\n",
        "        return pd.to_datetime(x, errors=\"coerce\")\n",
        "    except Exception:\n",
        "        try:\n",
        "            return pd.to_datetime(dtparser.parse(str(x)), errors=\"coerce\")\n",
        "        except Exception:\n",
        "            return pd.NaT\n",
        "\n",
        "def coerce_numeric(series: pd.Series) -> pd.Series:\n",
        "    \"\"\"Convierte strings '1,234.5' o '1.234,5' y otros a float; deja NaN si no se puede.\"\"\"\n",
        "    s = series.astype(str).str.replace(r\"[^\\d\\-\\.,]\", \"\", regex=True).str.strip()\n",
        "    # Si hay comas y puntos: asume 1,234.56 (ingl√©s) ‚Üí quita comas\n",
        "    s = pd.Series(np.where(s.str.contains(\",\") & s.str.contains(r\"\\.\"), s.str.replace(\",\", \"\", regex=False), s))\n",
        "    # Si hay comas pero no puntos: asume decimal con coma (1.234,56 ‚Üí 1234.56)\n",
        "    s = pd.Series(np.where((~pd.isna(s)) & (pd.Series(s).str.contains(\",\") & ~pd.Series(s).str.contains(r\"\\.\")),\n",
        "                 pd.Series(s).str.replace(\".\", \"\", regex=False).str.replace(\",\", \".\", regex=False),\n",
        "                 s))\n",
        "    out = pd.to_numeric(pd.Series(s), errors=\"coerce\")\n",
        "    return out\n",
        "\n",
        "def standardize_column_names(cols: List[str]) -> List[str]:\n",
        "    \"\"\"Normaliza nombres t√≠picos para mapear a EXPECTED_COLS.\"\"\"\n",
        "    mapping = {\n",
        "        r\"^pm\\s*10$\":\"PM10\",\n",
        "        r\"^pm10$\":\"PM10\",\n",
        "        r\"^pm\\s*2\\.?5$\":\"PM2.5\",\n",
        "        r\"^pm2\\.?5$\":\"PM2.5\",\n",
        "        r\"^o3$\":\"O3\",\n",
        "        r\"^no$\":\"NO\",\n",
        "        r\"^no2$\":\"NO2\",\n",
        "        r\"^nox$\":\"NOx\",\n",
        "        r\"^so2$\":\"SO2\",\n",
        "        r\"^co$\":\"CO\",\n",
        "        r\"^rh$\":\"RH\",\n",
        "        r\"^ws$\":\"WS\",\n",
        "        r\"^(temp|temperature)$\":\"TEMP\",\n",
        "        r\"^sr$\":\"SR\",\n",
        "        r\"^bp$\":\"BP\",\n",
        "        r\"^wd$\":\"WD\",\n",
        "        r\"^(rain|rainf|rainfall|precip.*)$\":\"RAINF\",\n",
        "        r\"^(date|datetime|fecha.*hora|fecha_hora|time.*)$\":TIME_COL,\n",
        "        r\"^(estacion|estaci√≥n|station)$\":\"STATION\",\n",
        "    }\n",
        "    new_cols = []\n",
        "    for c in cols:\n",
        "        c0 = str(c).strip()\n",
        "        c1 = re.sub(r\"\\s+\", \" \", c0)\n",
        "        c2 = c1.upper()\n",
        "        new = c2\n",
        "        for pat, tgt in mapping.items():\n",
        "            if re.match(pat, c2, flags=re.IGNORECASE):\n",
        "                new = tgt\n",
        "                break\n",
        "        new_cols.append(new)\n",
        "    return new_cols\n",
        "\n",
        "def add_station_if_missing(df: pd.DataFrame, station_name: str) -> pd.DataFrame:\n",
        "    if \"STATION\" not in df.columns:\n",
        "        df[\"STATION\"] = station_name\n",
        "    return df\n",
        "\n",
        "def concat_sheets_with_station(reader, sheet_names):\n",
        "    dfs = []\n",
        "    for sh in sheet_names:\n",
        "        try:\n",
        "            df = reader.parse(sh)\n",
        "        except Exception:\n",
        "            df = reader.parse(sh, header=0)\n",
        "        df.columns = standardize_column_names(list(df.columns))\n",
        "        df = add_station_if_missing(df, sh)\n",
        "        dfs.append(df)\n",
        "    return pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "def read_numbers_as_dataframe(path_numbers: str) -> pd.DataFrame:\n",
        "    \"\"\"Lee un archivo .numbers como tablas y concatena.\"\"\"\n",
        "    try:\n",
        "        from numbers_parser import Document\n",
        "    except ImportError as e:\n",
        "        raise RuntimeError(\"Falta instalar 'numbers-parser'. Ejecuta: !pip install numbers-parser\") from e\n",
        "\n",
        "    doc = Document(path_numbers)\n",
        "    frames = []\n",
        "    for sheet in doc.sheets:\n",
        "        for table in sheet.tables:\n",
        "            data = table.rows(values_only=True)\n",
        "            if not data:\n",
        "                continue\n",
        "            df = pd.DataFrame(data[1:], columns=data[0]) if len(data) > 1 else pd.DataFrame(columns=data[0])\n",
        "            df.columns = standardize_column_names(df.columns.tolist())\n",
        "            df = add_station_if_missing(df, sheet.name)\n",
        "            frames.append(df)\n",
        "    if not frames:\n",
        "        return pd.DataFrame(columns=[TIME_COL, \"STATION\"] + EXPECTED_COLS)\n",
        "    return pd.concat(frames, ignore_index=True)\n",
        "\n",
        "def read_data() -> pd.DataFrame:\n",
        "    if READ_NUMBERS and os.path.exists(PATH_DATA_NUMBERS):\n",
        "        df = read_numbers_as_dataframe(PATH_DATA_NUMBERS)\n",
        "    elif os.path.exists(PATH_DATA_XLSX):\n",
        "        xls = pd.ExcelFile(PATH_DATA_XLSX)\n",
        "        df = concat_sheets_with_station(xls, xls.sheet_names)\n",
        "    else:\n",
        "        raise FileNotFoundError(\"No se encontr√≥ el archivo .numbers ni el .xlsx. Sube uno de los dos con el nombre esperado.\")\n",
        "    # Normaliza nombres y asegura columnas esperadas\n",
        "    df.columns = standardize_column_names(df.columns.tolist())\n",
        "    for c in EXPECTED_COLS:\n",
        "        if c not in df.columns:\n",
        "            df[c] = np.nan\n",
        "    if TIME_COL in df.columns:\n",
        "        df[TIME_COL] = df[TIME_COL].apply(try_parse_datetime)\n",
        "    return df\n",
        "\n",
        "def read_etiquetas():\n",
        "    \"\"\"Lee un diccionario de etiquetas si existe; si no, retorna None.\"\"\"\n",
        "    if not os.path.exists(PATH_ETIQUETAS):\n",
        "        return None\n",
        "    try:\n",
        "        et = pd.read_excel(PATH_ETIQUETAS)\n",
        "        return et\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# =========================================\n",
        "# 3) 1) Comprensi√≥n de los datos (versi√≥n robusta)\n",
        "# =========================================\n",
        "\n",
        "def describe_variables(df: pd.DataFrame, etiquetas: pd.DataFrame | None) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Devuelve un dataframe con:\n",
        "        nombre, descripcion, tipo, valores_posibles, nulos\n",
        "    Soporta num√©ricas, categ√≥ricas, booleanas y fecha/hora.\n",
        "    \"\"\"\n",
        "    summary = []\n",
        "    for c in df.columns:\n",
        "        ser = df[c]\n",
        "        n_null = int(ser.isna().sum())\n",
        "\n",
        "        if is_datetime64_any_dtype(ser):\n",
        "            tipo = \"Fecha/Hora\"\n",
        "            if ser.notna().any():\n",
        "                vmin = pd.to_datetime(ser.min())\n",
        "                vmax = pd.to_datetime(ser.max())\n",
        "                vals = [vmin.isoformat(), vmax.isoformat()]\n",
        "            else:\n",
        "                vals = [np.nan, np.nan]\n",
        "\n",
        "        elif is_bool_dtype(ser):\n",
        "            tipo = \"Categ√≥rico (bool)\"\n",
        "            uniq = ser.dropna().unique().tolist()\n",
        "            vals = uniq[:20] + ([\"...\"] if len(uniq) > 20 else [])\n",
        "\n",
        "        elif is_categorical_dtype(ser) or ser.dtype == \"object\":\n",
        "            tipo = \"Categ√≥rico\"\n",
        "            uniq = ser.dropna().unique().tolist()\n",
        "            vals = uniq[:20] + ([\"...\"] if len(uniq) > 20 else [])\n",
        "\n",
        "        elif is_numeric_dtype(ser):\n",
        "            tipo = \"Num√©rico\"\n",
        "            if ser.notna().any():\n",
        "                vmin = np.nanmin(ser.astype(float))\n",
        "                vmax = np.nanmax(ser.astype(float))\n",
        "                vals = [float(vmin), float(vmax)]\n",
        "            else:\n",
        "                vals = [np.nan, np.nan]\n",
        "\n",
        "        else:\n",
        "            tipo = str(ser.dtype)\n",
        "            uniq = ser.dropna().unique().tolist()\n",
        "            vals = uniq[:20] + ([\"...\"] if len(uniq) > 20 else [])\n",
        "\n",
        "        summary.append({\n",
        "            \"variable\": c,\n",
        "            \"descripcion\": None,\n",
        "            \"tipo\": tipo,\n",
        "            \"valores_posibles\": vals,\n",
        "            \"nulos\": n_null\n",
        "        })\n",
        "\n",
        "    desc_df = pd.DataFrame(summary)\n",
        "\n",
        "    # Integraci√≥n opcional con Etiquetas.xlsx\n",
        "    if etiquetas is not None:\n",
        "        et = etiquetas.copy()\n",
        "        if \"variable\" not in et.columns:\n",
        "            cand = [col for col in et.columns if \"var\" in col.lower() or \"nombre\" in col.lower()]\n",
        "            if cand:\n",
        "                et = et.rename(columns={cand[0]: \"variable\"})\n",
        "        for candidate, target in [\n",
        "            (\"descripcion\",\"descripcion\"),\n",
        "            (\"descripci√≥n\",\"descripcion\"),\n",
        "            (\"tipo\",\"tipo_usuario\"),\n",
        "            (\"valores\",\"valores_usuario\"),\n",
        "            (\"valores_posibles\",\"valores_usuario\")\n",
        "        ]:\n",
        "            if candidate in et.columns and target not in et.columns:\n",
        "                et = et.rename(columns={candidate: target})\n",
        "        if \"variable\" in et.columns:\n",
        "            desc_df = desc_df.merge(et, on=\"variable\", how=\"left\")\n",
        "            if \"tipo_usuario\" in desc_df.columns:\n",
        "                desc_df[\"tipo\"] = desc_df[\"tipo_usuario\"].fillna(desc_df[\"tipo\"])\n",
        "            if \"valores_usuario\" in desc_df.columns:\n",
        "                desc_df[\"valores_posibles\"] = desc_df[\"valores_usuario\"].combine_first(desc_df[\"valores_posibles\"])\n",
        "            for col in [\"tipo_usuario\", \"valores_usuario\"]:\n",
        "                if col in desc_df.columns:\n",
        "                    desc_df.drop(columns=[col], inplace=True)\n",
        "\n",
        "    return desc_df\n",
        "\n",
        "def quality_checks(df: pd.DataFrame) -> dict:\n",
        "    qc = {}\n",
        "    qc[\"shape\"] = df.shape\n",
        "    qc[\"missing_by_col\"] = df.isna().sum().sort_values(ascending=False).to_dict()\n",
        "    qc[\"has_infinite\"] = np.isinf(df.select_dtypes(include=[np.number]).to_numpy()).any()\n",
        "    qc[\"duplicated_rows\"] = int(df.duplicated().sum())\n",
        "    return qc\n",
        "\n",
        "# =========================================\n",
        "# 4) 2) Preparaci√≥n de los datos\n",
        "# =========================================\n",
        "\n",
        "def select_and_explain(df: pd.DataFrame) -> Tuple[pd.DataFrame, str]:\n",
        "    \"\"\"Selecciona columnas de tiempo, estaci√≥n y variables est√°ndar.\"\"\"\n",
        "    keep = [TIME_COL, \"STATION\"] + EXPECTED_COLS\n",
        "    keep = [c for c in keep if c in df.columns]\n",
        "    out = df[keep].copy()\n",
        "    explanation = (\n",
        "        \"Se seleccionaron las columnas de tiempo (DATETIME), STATION y variables de medici√≥n est√°ndar. \"\n",
        "        \"Se excluyeron columnas auxiliares para evitar ruido y garantizar comparabilidad.\"\n",
        "    )\n",
        "    return out, explanation\n",
        "\n",
        "def identify_targets(df: pd.DataFrame) -> List[str]:\n",
        "    \"\"\"Columnas objetivo sugeridas (aj√∫stalo a tu an√°lisis).\"\"\"\n",
        "    return [c for c in [\"PM2.5\",\"PM10\"] if c in df.columns]\n",
        "\n",
        "def fix_types(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Convierte mediciones a num√©rico\n",
        "    for c in EXPECTED_COLS:\n",
        "        if c in df.columns:\n",
        "            df[c] = coerce_numeric(df[c])\n",
        "    # Asegura datetime y variables derivadas de tiempo\n",
        "    if TIME_COL in df.columns:\n",
        "        if not is_datetime64_any_dtype(df[TIME_COL]):\n",
        "            df[TIME_COL] = pd.to_datetime(df[TIME_COL], errors=\"coerce\")\n",
        "        df[\"YEAR\"] = df[TIME_COL].dt.year\n",
        "        df[\"MONTH\"] = df[TIME_COL].dt.month\n",
        "        df[\"DAY\"] = df[TIME_COL].dt.day\n",
        "        df[\"HOUR\"] = df[TIME_COL].dt.hour\n",
        "    return df\n",
        "\n",
        "def apply_yearly_ranges(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Marca como NaN los valores fuera de rango conforme al a√±o de la fila.\"\"\"\n",
        "    if \"YEAR\" not in df.columns:\n",
        "        return df\n",
        "    def clip_row(row):\n",
        "        yr = row[\"YEAR\"]\n",
        "        ranges = RANGOS_POR_ANIO.get(int(yr) if not pd.isna(yr) else yr, {})\n",
        "        for col, (lo, hi) in ranges.items():\n",
        "            if col in row and pd.notna(row[col]):\n",
        "                v = row[col]\n",
        "                if (v < lo) or (v > hi):\n",
        "                    row[col] = np.nan\n",
        "        return row\n",
        "    return df.apply(clip_row, axis=1)\n",
        "\n",
        "def drop_duplicates(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    before = len(df)\n",
        "    df = df.drop_duplicates()\n",
        "    after = len(df)\n",
        "    print(f\"Duplicados eliminados (filas exactas): {before - after}\")\n",
        "    if TIME_COL in df.columns and \"STATION\" in df.columns:\n",
        "        before = len(df)\n",
        "        df = df.sort_values(by=[TIME_COL]).drop_duplicates(subset=[\"STATION\", TIME_COL], keep=\"first\")\n",
        "        after = len(df)\n",
        "        print(f\"Duplicados por clave (STATION, DATETIME): {before - after}\")\n",
        "    return df\n",
        "\n",
        "def handle_missing(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Manejo de NA:\n",
        "      - Interpolaci√≥n temporal por estaci√≥n para series num√©ricas (con √≠ndice de tiempo).\n",
        "      - ffill/bfill cortos.\n",
        "      - Imputaci√≥n global opcional (media/mediana).\n",
        "    \"\"\"\n",
        "    num_cols = [c for c in df.columns if c in EXPECTED_COLS]\n",
        "    if TIME_COL in df.columns and \"STATION\" in df.columns:\n",
        "        # Operar por estaci√≥n con √≠ndice de tiempo para usar method=\"time\"\n",
        "        def _interpolate_group(g):\n",
        "            g = g.sort_values(TIME_COL)\n",
        "            g_idx = g.set_index(TIME_COL)\n",
        "            for c in num_cols:\n",
        "                s = g_idx[c]\n",
        "                s = s.interpolate(method=\"time\")\n",
        "                s = s.ffill().bfill()\n",
        "                g_idx[c] = s\n",
        "            return g_idx.reset_index()\n",
        "        df = df.groupby(\"STATION\", group_keys=False).apply(_interpolate_group)\n",
        "\n",
        "    if IMPUTE_STRATEGY in (\"mean\",\"median\"):\n",
        "        imputer = SimpleImputer(strategy=IMPUTE_STRATEGY)\n",
        "        df[num_cols] = imputer.fit_transform(df[num_cols])\n",
        "\n",
        "    return df\n",
        "\n",
        "def handle_categoricals(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    cat_cols = [c for c in df.columns if df[c].dtype == \"object\" or str(df[c].dtype).startswith(\"category\")]\n",
        "    if CREATE_DUMMIES and cat_cols:\n",
        "        df = pd.get_dummies(df, columns=cat_cols, drop_first=True, dtype=int)\n",
        "    return df\n",
        "\n",
        "def iqr_outlier_mask(x: pd.Series, k: float = 1.5):\n",
        "    q1, q3 = np.nanpercentile(x, [25, 75])\n",
        "    iqr = q3 - q1\n",
        "    lo, hi = q1 - k*iqr, q3 + k*iqr\n",
        "    return (x < lo) | (x > hi)\n",
        "\n",
        "def handle_outliers(df: pd.DataFrame, k: float = 1.5) -> pd.DataFrame:\n",
        "    \"\"\"Manejo de at√≠picos (IQR) por estaci√≥n y a√±o. Se marcan como NaN.\"\"\"\n",
        "    if \"STATION\" not in df.columns or \"YEAR\" not in df.columns:\n",
        "        return df\n",
        "    num_cols = [c for c in EXPECTED_COLS if c in df.columns]\n",
        "    def _proc(group):\n",
        "        for c in num_cols:\n",
        "            s = group[c]\n",
        "            if s.notna().sum() >= 12:\n",
        "                mask = iqr_outlier_mask(s, k=k)\n",
        "                group.loc[mask, c] = np.nan\n",
        "        return group\n",
        "    return df.groupby([\"STATION\",\"YEAR\"], group_keys=False).apply(_proc)\n",
        "\n",
        "# =========================================\n",
        "# 5) 3) Transformaci√≥n de Datos\n",
        "# =========================================\n",
        "\n",
        "def build_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Atributos derivados: componentes del viento y variables de calendario.\"\"\"\n",
        "    out = df.copy()\n",
        "    if \"WS\" in out.columns and \"WD\" in out.columns:\n",
        "        ws = out[\"WS\"].astype(float)\n",
        "        wd_rad = np.deg2rad(out[\"WD\"].astype(float))\n",
        "        out[\"WIND_U\"] = -ws * np.sin(wd_rad)\n",
        "        out[\"WIND_V\"] = -ws * np.cos(wd_rad)\n",
        "    if TIME_COL in out.columns:\n",
        "        out[\"WEEKDAY\"] = out[TIME_COL].dt.weekday  # 0=lun\n",
        "        out[\"IS_WEEKEND\"] = (out[\"WEEKDAY\"] >= 5).astype(int)\n",
        "    return out\n",
        "\n",
        "def scale_numeric(df: pd.DataFrame) -> Tuple[pd.DataFrame, dict]:\n",
        "    if SCALING not in (\"standard\",\"minmax\"):\n",
        "        return df, {}\n",
        "    num_cols = [c for c in df.columns if c in EXPECTED_COLS or c in [\"WIND_U\",\"WIND_V\"]]\n",
        "    num_cols = [c for c in num_cols if c in df.columns]\n",
        "    scaler = StandardScaler() if SCALING==\"standard\" else MinMaxScaler()\n",
        "    scaled = df.copy()\n",
        "    scaled[num_cols] = scaler.fit_transform(scaled[num_cols])\n",
        "    info = {\"scaler\": SCALING, \"columns\": num_cols}\n",
        "    return scaled, info\n",
        "\n",
        "def bin_numeric(df: pd.DataFrame, cols: List[str]) -> Tuple[pd.DataFrame, dict]:\n",
        "    if BINNING not in (\"quantile\",\"uniform\") or not cols:\n",
        "        return df, {}\n",
        "    binner = KBinsDiscretizer(n_bins=N_BINS, encode=\"ordinal\",\n",
        "                              strategy=(\"quantile\" if BINNING==\"quantile\" else \"uniform\"))\n",
        "    x = df[cols].copy()\n",
        "    mask = x.notna().all(axis=1)\n",
        "    x_notna = x[mask]\n",
        "    out = df.copy()\n",
        "    out.loc[mask, [f\"{c}_BIN\" for c in cols]] = binner.fit_transform(x_notna)\n",
        "    info = {\"binner\": BINNING, \"columns\": cols, \"bins\": N_BINS}\n",
        "    return out, info\n",
        "\n",
        "# =========================================\n",
        "# 6) 4) Reformateo / Exportaci√≥n\n",
        "# =========================================\n",
        "\n",
        "def tidy_and_export(df: pd.DataFrame, outdir=\"/content/clean\"):\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    # Exporta completo\n",
        "    full_path = os.path.join(outdir, \"air_quality_clean_full.parquet\")\n",
        "    df.to_parquet(full_path, index=False)\n",
        "    print(f\"‚úÖ Exportado dataset completo: {full_path}\")\n",
        "\n",
        "    # Por a√±o\n",
        "    if \"YEAR\" in df.columns:\n",
        "        for yr, dfg in df.groupby(\"YEAR\"):\n",
        "            p = os.path.join(outdir, f\"air_quality_clean_{int(yr)}.csv\")\n",
        "            dfg.to_csv(p, index=False)\n",
        "    # Por estaci√≥n y a√±o\n",
        "    if \"STATION\" in df.columns and \"YEAR\" in df.columns:\n",
        "        for (st, yr), dfg in df.groupby([\"STATION\",\"YEAR\"]):\n",
        "            fname = re.sub(r\"[^A-Za-z0-9\\-]+\",\"_\", str(st))\n",
        "            p = os.path.join(outdir, f\"clean_{fname}_{int(yr)}.csv\")\n",
        "            dfg.to_csv(p, index=False)\n",
        "    print(\"üì¶ Exportaciones por a√±o y por estaci√≥n listas en:\", outdir)\n",
        "\n",
        "# =========================================\n",
        "# 7) RUN: pipeline maestro\n",
        "# =========================================\n",
        "\n",
        "def main():\n",
        "    print(\"=== Cargando datos ===\")\n",
        "    df = read_data()\n",
        "    print(\"Dimensi√≥n inicial:\", df.shape)\n",
        "\n",
        "    # -------- Comprensi√≥n de datos --------\n",
        "    print(\"\\n=== 1) Comprensi√≥n de los datos ===\")\n",
        "    etiquetas = read_etiquetas()\n",
        "    desc = describe_variables(df, etiquetas)\n",
        "    print(\"Dimensi√≥n del dataset:\", df.shape)\n",
        "    print(\"\\nDiccionario de variables (primeras filas):\")\n",
        "    display(desc.head(30))\n",
        "\n",
        "    qc = quality_checks(df)\n",
        "    print(\"\\nCalidad de datos:\")\n",
        "    print(\" - Registros, Columnas:\", qc[\"shape\"])\n",
        "    print(\" - Faltantes por columna (top 10):\", dict(list(qc[\"missing_by_col\"].items())[:10]))\n",
        "    print(\" - Valores infinitos:\", qc[\"has_infinite\"])\n",
        "    print(\" - Filas duplicadas totales:\", qc[\"duplicated_rows\"])\n",
        "\n",
        "    # -------- Preparaci√≥n --------\n",
        "    print(\"\\n=== 2) Preparaci√≥n de los datos ===\")\n",
        "    df, rationale = select_and_explain(df)\n",
        "    print(\"Racional de selecci√≥n:\\n\", rationale)\n",
        "\n",
        "    df = fix_types(df)                # tipos + YEAR/MONTH/DAY/HOUR\n",
        "    df = apply_yearly_ranges(df)      # rangos por a√±o del PDF\n",
        "    df = drop_duplicates(df)          # duplicados\n",
        "    df = handle_outliers(df, k=1.5)   # outliers ‚Üí NaN\n",
        "    df = handle_missing(df)           # interpolaci√≥n por estaci√≥n + ffill/bfill + imputaci√≥n opcional\n",
        "\n",
        "    targets = identify_targets(df)\n",
        "    print(\"Columnas objetivo sugeridas:\", targets)\n",
        "\n",
        "    df = handle_categoricals(df)      # dummies para categ√≥ricas (si aplica)\n",
        "\n",
        "    # -------- Transformaci√≥n --------\n",
        "    print(\"\\n=== 3) Transformaci√≥n de Datos ===\")\n",
        "    df = build_features(df)\n",
        "\n",
        "    df_scaled, scale_info = scale_numeric(df)\n",
        "    if scale_info:\n",
        "        print(\"Escalado aplicado:\", scale_info)\n",
        "\n",
        "    bin_cols = [c for c in [\"PM2.5\",\"PM10\"] if c in df_scaled.columns]\n",
        "    df_binned, bin_info = bin_numeric(df_scaled, bin_cols)\n",
        "    if bin_info:\n",
        "        print(\"Binning aplicado:\", bin_info)\n",
        "\n",
        "    # -------- Reformateo / Exportaci√≥n --------\n",
        "    print(\"\\n=== 4) Reformateo / Exportaci√≥n ===\")\n",
        "    tidy_and_export(df_binned)\n",
        "\n",
        "    # Reporte final breve\n",
        "    print(\"\\n=== Resumen R√ÅPIDO ===\")\n",
        "    print(\"Filas/Columnas finales:\", df_binned.shape)\n",
        "    print(\"NA totales:\", int(df_binned.isna().sum().sum()))\n",
        "    print(\"Columnas creadas (derivadas):\", [c for c in [\"WIND_U\",\"WIND_V\",\"WEEKDAY\",\"IS_WEEKEND\"] if c in df_binned.columns])\n",
        "    print(\"Listo ‚úÖ\")\n",
        "\n",
        "# Ejecutar\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "czQITkg9UGcU",
        "outputId": "dda63ae8-5992-4933-f1da-c36f6f0814d0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Cargando datos ===\n",
            "Dimensi√≥n inicial: (13883, 260)\n",
            "\n",
            "=== 1) Comprensi√≥n de los datos ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1828814518.py:248: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  elif is_categorical_dtype(ser) or ser.dtype == \"object\":\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensi√≥n del dataset: (13883, 260)\n",
            "\n",
            "Diccionario de variables (primeras filas):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       variable descripcion        tipo  \\\n",
              "0    UNNAMED: 0        None    Num√©rico   \n",
              "1    UNNAMED: 1        None  Categ√≥rico   \n",
              "2    UNNAMED: 2        None  Categ√≥rico   \n",
              "3    UNNAMED: 3        None  Categ√≥rico   \n",
              "4       STATION        None  Categ√≥rico   \n",
              "5      DATETIME        None  Fecha/Hora   \n",
              "6       SURESTE        None  Categ√≥rico   \n",
              "7     SURESTE.1        None  Categ√≥rico   \n",
              "8     SURESTE.2        None  Categ√≥rico   \n",
              "9     SURESTE.3        None  Categ√≥rico   \n",
              "10    SURESTE.4        None  Categ√≥rico   \n",
              "11    SURESTE.5        None  Categ√≥rico   \n",
              "12    SURESTE.6        None  Categ√≥rico   \n",
              "13    SURESTE.7        None  Categ√≥rico   \n",
              "14    SURESTE.8        None  Categ√≥rico   \n",
              "15    SURESTE.9        None  Categ√≥rico   \n",
              "16   SURESTE.10        None  Categ√≥rico   \n",
              "17   SURESTE.11        None  Categ√≥rico   \n",
              "18   SURESTE.12        None  Categ√≥rico   \n",
              "19   SURESTE.13        None  Categ√≥rico   \n",
              "20   SURESTE.14        None  Categ√≥rico   \n",
              "21  UNNAMED: 16        None    Num√©rico   \n",
              "22      NORESTE        None  Categ√≥rico   \n",
              "23    NORESTE.1        None  Categ√≥rico   \n",
              "24    NORESTE.2        None  Categ√≥rico   \n",
              "25    NORESTE.3        None  Categ√≥rico   \n",
              "26    NORESTE.4        None  Categ√≥rico   \n",
              "27    NORESTE.5        None  Categ√≥rico   \n",
              "28    NORESTE.6        None  Categ√≥rico   \n",
              "29    NORESTE.7        None  Categ√≥rico   \n",
              "\n",
              "                                     valores_posibles  nulos  \n",
              "0                                          [nan, nan]  13883  \n",
              "1   [This document was exported from Numbers.  Eac...  13879  \n",
              "2                       [Numbers Table Name, Table 1]  13880  \n",
              "3   [Excel Worksheet Name, Param_horarios_Estacion...  13880  \n",
              "4         [Export Summary, Param_horarios_Estaciones]      0  \n",
              "5          [2023-01-01T00:00:00, 2024-07-31T23:00:00]     13  \n",
              "6   [CO, ppm, 2.37, 2.12, 2.05, 2.5, 1.94, 1.35, 1...    196  \n",
              "7   [NO, ppb, 54.5, 38.7, 60.5, 42.3, 10.2, 7.8, 5...    377  \n",
              "8   [NO2, ppb, 32.6, 30.3, 28.8, 29.1, 25.7, 23.1,...    164  \n",
              "9   [NOX, ppb, 87.1, 68.9, 67.4, 89.4, 67.7, 33.2,...    165  \n",
              "10  [O3, ppb, 3, 4, 10, 13, 16, 17, 24, 31, 53, 54...    417  \n",
              "11  [PM10, ug/m3, 110, 116, 117, 135, 132, 96, 59,...    393  \n",
              "12  [PM2.5, ug/m3, 68, 67.18, 75.12, 82.81, 59.56,...   3693  \n",
              "13  [PRS, mmhg, 721.7, 721.5, 721.1, 720.8, 720.7,...    141  \n",
              "14  [RAINF, mm/hr, 0, 0.02, 0.04, 0.03, 0.01, 0.74...    143  \n",
              "15  [RH, %, 68, 72, 71, 73, 59, 51, 39, 37, 28, 24...    176  \n",
              "16  [SO2, ppb, 3.5, 3.4, 3.6, 3.8, 3, 3.3, 3.2, 5....    233  \n",
              "17  [SR, KW/m2, 0, 0.006, 0.089, 0.229, 0.328, 0.3...     70  \n",
              "18  [TOUT, degC, 16.39, 15.17, 14.82, 15.51, 13.81...    138  \n",
              "19  [WSR, KMPH, 3.2, 3.3, 3.7, 3.6, 4.9, 6.8, 8.4,...    139  \n",
              "20  [WDV, DEG, 257, 278, 197, 271, 284, 286, 287, ...    141  \n",
              "21                                         [nan, nan]  13883  \n",
              "22  [CO, ppm, 3.4, 4.3, 4.28, 3.77, 2.98, 2.1, 3.0...    599  \n",
              "23  [NO, ppb, 30.4, 67.2, 63.9, 57.2, 41.9, 16.5, ...    299  \n",
              "24  [NO2, ppb, 43, 44.4, 41.5, 42.3, 39.9, 35.1, 3...    227  \n",
              "25  [NOX, ppb, 73.4, 111.6, 105.5, 99.5, 81.8, 51....    229  \n",
              "26  [O3, ppb, 7, 8, 6, 5, 4, 11, 21, 34, 43, 47, 5...    683  \n",
              "27  [PM10, ug/m3, 222, 311, 723, 473, 372, 285, 17...    447  \n",
              "28  [PM2.5, ug/m3, 400, 349, 260, 157, 195, 90, 11...   1567  \n",
              "29  [PRS, mmhg, 718.4, 718.1, 717.8, 717.6, 718, 7...    254  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32d5e39a-1f13-4895-b07c-751118bd62e1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>variable</th>\n",
              "      <th>descripcion</th>\n",
              "      <th>tipo</th>\n",
              "      <th>valores_posibles</th>\n",
              "      <th>nulos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>UNNAMED: 0</td>\n",
              "      <td>None</td>\n",
              "      <td>Num√©rico</td>\n",
              "      <td>[nan, nan]</td>\n",
              "      <td>13883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>UNNAMED: 1</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[This document was exported from Numbers.  Eac...</td>\n",
              "      <td>13879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>UNNAMED: 2</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[Numbers Table Name, Table 1]</td>\n",
              "      <td>13880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>UNNAMED: 3</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[Excel Worksheet Name, Param_horarios_Estacion...</td>\n",
              "      <td>13880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>STATION</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[Export Summary, Param_horarios_Estaciones]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>DATETIME</td>\n",
              "      <td>None</td>\n",
              "      <td>Fecha/Hora</td>\n",
              "      <td>[2023-01-01T00:00:00, 2024-07-31T23:00:00]</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SURESTE</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[CO, ppm, 2.37, 2.12, 2.05, 2.5, 1.94, 1.35, 1...</td>\n",
              "      <td>196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SURESTE.1</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[NO, ppb, 54.5, 38.7, 60.5, 42.3, 10.2, 7.8, 5...</td>\n",
              "      <td>377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SURESTE.2</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[NO2, ppb, 32.6, 30.3, 28.8, 29.1, 25.7, 23.1,...</td>\n",
              "      <td>164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SURESTE.3</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[NOX, ppb, 87.1, 68.9, 67.4, 89.4, 67.7, 33.2,...</td>\n",
              "      <td>165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>SURESTE.4</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[O3, ppb, 3, 4, 10, 13, 16, 17, 24, 31, 53, 54...</td>\n",
              "      <td>417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>SURESTE.5</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[PM10, ug/m3, 110, 116, 117, 135, 132, 96, 59,...</td>\n",
              "      <td>393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>SURESTE.6</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[PM2.5, ug/m3, 68, 67.18, 75.12, 82.81, 59.56,...</td>\n",
              "      <td>3693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>SURESTE.7</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[PRS, mmhg, 721.7, 721.5, 721.1, 720.8, 720.7,...</td>\n",
              "      <td>141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>SURESTE.8</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[RAINF, mm/hr, 0, 0.02, 0.04, 0.03, 0.01, 0.74...</td>\n",
              "      <td>143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>SURESTE.9</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[RH, %, 68, 72, 71, 73, 59, 51, 39, 37, 28, 24...</td>\n",
              "      <td>176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>SURESTE.10</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[SO2, ppb, 3.5, 3.4, 3.6, 3.8, 3, 3.3, 3.2, 5....</td>\n",
              "      <td>233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>SURESTE.11</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[SR, KW/m2, 0, 0.006, 0.089, 0.229, 0.328, 0.3...</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>SURESTE.12</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[TOUT, degC, 16.39, 15.17, 14.82, 15.51, 13.81...</td>\n",
              "      <td>138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>SURESTE.13</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[WSR, KMPH, 3.2, 3.3, 3.7, 3.6, 4.9, 6.8, 8.4,...</td>\n",
              "      <td>139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>SURESTE.14</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[WDV, DEG, 257, 278, 197, 271, 284, 286, 287, ...</td>\n",
              "      <td>141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>UNNAMED: 16</td>\n",
              "      <td>None</td>\n",
              "      <td>Num√©rico</td>\n",
              "      <td>[nan, nan]</td>\n",
              "      <td>13883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>NORESTE</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[CO, ppm, 3.4, 4.3, 4.28, 3.77, 2.98, 2.1, 3.0...</td>\n",
              "      <td>599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>NORESTE.1</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[NO, ppb, 30.4, 67.2, 63.9, 57.2, 41.9, 16.5, ...</td>\n",
              "      <td>299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>NORESTE.2</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[NO2, ppb, 43, 44.4, 41.5, 42.3, 39.9, 35.1, 3...</td>\n",
              "      <td>227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>NORESTE.3</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[NOX, ppb, 73.4, 111.6, 105.5, 99.5, 81.8, 51....</td>\n",
              "      <td>229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>NORESTE.4</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[O3, ppb, 7, 8, 6, 5, 4, 11, 21, 34, 43, 47, 5...</td>\n",
              "      <td>683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>NORESTE.5</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[PM10, ug/m3, 222, 311, 723, 473, 372, 285, 17...</td>\n",
              "      <td>447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>NORESTE.6</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[PM2.5, ug/m3, 400, 349, 260, 157, 195, 90, 11...</td>\n",
              "      <td>1567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>NORESTE.7</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[PRS, mmhg, 718.4, 718.1, 717.8, 717.6, 718, 7...</td>\n",
              "      <td>254</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32d5e39a-1f13-4895-b07c-751118bd62e1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-32d5e39a-1f13-4895-b07c-751118bd62e1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-32d5e39a-1f13-4895-b07c-751118bd62e1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4fc7727d-02f4-4c32-b0c7-2328dc5fbf08\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4fc7727d-02f4-4c32-b0c7-2328dc5fbf08')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4fc7727d-02f4-4c32-b0c7-2328dc5fbf08 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Calidad de datos:\n",
            " - Registros, Columnas: (13883, 260)\n",
            " - Faltantes por columna (top 10): {'RAINF': 13883, 'UNNAMED: 0': 13883, 'UNNAMED: 224': 13883, 'UNNAMED: 16': 13883, 'UNNAMED: 208': 13883, 'UNNAMED: 32': 13883, 'UNNAMED: 192': 13883, 'O3': 13883, 'SO2': 13883, 'UNNAMED: 112': 13883}\n",
            " - Valores infinitos: False\n",
            " - Filas duplicadas totales: 4\n",
            "\n",
            "=== 2) Preparaci√≥n de los datos ===\n",
            "Racional de selecci√≥n:\n",
            " Se seleccionaron las columnas de tiempo (DATETIME), STATION y variables de medici√≥n est√°ndar. Se excluyeron columnas auxiliares para evitar ruido y garantizar comparabilidad.\n",
            "Duplicados eliminados (filas exactas): 11\n",
            "Duplicados por clave (STATION, DATETIME): 0\n",
            "Columnas objetivo sugeridas: ['PM2.5', 'PM10']\n",
            "\n",
            "=== 3) Transformaci√≥n de Datos ===\n",
            "Escalado aplicado: {'scaler': 'standard', 'columns': ['PM10', 'PM2.5', 'O3', 'NO', 'NO2', 'NOx', 'SO2', 'CO', 'RH', 'WS', 'TEMP', 'SR', 'BP', 'WD', 'RAINF', 'WIND_U', 'WIND_V']}\n",
            "\n",
            "=== 4) Reformateo / Exportaci√≥n ===\n",
            "‚úÖ Exportado dataset completo: /content/clean/air_quality_clean_full.parquet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1828814518.py:425: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return df.groupby([\"STATION\",\"YEAR\"], group_keys=False).apply(_proc)\n",
            "/tmp/ipython-input-1828814518.py:393: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df = df.groupby(\"STATION\", group_keys=False).apply(_interpolate_group)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Exportaciones por a√±o y por estaci√≥n listas en: /content/clean\n",
            "\n",
            "=== Resumen R√ÅPIDO ===\n",
            "Filas/Columnas finales: (13870, 24)\n",
            "NA totales: 235790\n",
            "Columnas creadas (derivadas): ['WIND_U', 'WIND_V', 'WEEKDAY', 'IS_WEEKEND']\n",
            "Listo ‚úÖ\n"
          ]
        }
      ]
    }
  ]
}
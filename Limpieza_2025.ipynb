{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QM5G3_uSWpik"
      },
      "outputs": [],
      "source": [
        "# ============================\n",
        "# CHUNK 0: Par√°metros & Setup\n",
        "# ============================\n",
        "# Requisitos (ejecuta si hace falta):\n",
        "# !pip install pandas numpy openpyxl xlrd scikit-learn python-dateutil\n",
        "\n",
        "import os, re, warnings\n",
        "from typing import Dict, Tuple, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from dateutil import parser as dtparser\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, KBinsDiscretizer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from pandas.api.types import (\n",
        "    is_numeric_dtype, is_datetime64_any_dtype, is_bool_dtype, is_categorical_dtype\n",
        ")\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# >>>>>>>>>>>> EDITA AQU√ç SI CAMBIA EL NOMBRE DEL ARCHIVO <<<<<<<<<<<<\n",
        "PATH_DATA_2025 = \"/content/DATOS HISTORICOS 2025_TODAS ESTACIONES.xlsx\"\n",
        "PATH_ETIQUETAS = \"/content/Etiquetas.xlsx\"\n",
        "\n",
        "# Flags de procesamiento (iguales al flujo 2023)\n",
        "CREATE_DUMMIES   = True\n",
        "IMPUTE_STRATEGY  = None        # None | \"median\" | \"mean\"\n",
        "SCALING          = \"standard\"  # None | \"standard\" | \"minmax\"\n",
        "BINNING          = None        # None | \"quantile\" | \"uniform\"\n",
        "N_BINS           = 5\n",
        "\n",
        "EXPECTED_COLS = [\"PM10\",\"PM2.5\",\"O3\",\"NO\",\"NO2\",\"NOx\",\"SO2\",\"CO\",\"RH\",\"WS\",\"TEMP\",\"SR\",\"BP\",\"WD\",\"RAINF\"]\n",
        "TIME_COL      = \"DATETIME\"\n",
        "\n",
        "# Rangos por a√±o (incluye 2025)\n",
        "RANGOS_POR_ANIO: Dict[int, Dict[str, Tuple[float, float]]] = {\n",
        "    2020: {\"PM10\":(0,800),\"PM2.5\":(0,205.94),\"O3\":(0,153),\"NO\":(0,500),\"NO2\":(0,200),\"NOx\":(0,500),\n",
        "           \"SO2\":(0,200),\"CO\":(0,20),\"RH\":(0,100),\"WS\":(0,75),\"TEMP\":(0,41),\"SR\":(0,1),\"BP\":(690,750),\n",
        "           \"WD\":(0,360),\"RAINF\":(0,30)},\n",
        "    2021: {\"PM10\":(0,800),\"PM2.5\":(0,325),\"O3\":(0,175),\"NO\":(0,350),\"NO2\":(0,100),\"NOx\":(0,400),\n",
        "           \"SO2\":(0,300),\"CO\":(0,10),\"RH\":(0,100),\"WS\":(0,40),\"TEMP\":(-6.5,45),\"SR\":(0,1),\n",
        "           \"BP\":(690,740),\"WD\":(0,360),\"RAINF\":(0,80)},\n",
        "    2022: {\"PM10\":(0,999),\"PM2.5\":(0,450),\"O3\":(0,160),\"NO\":(0,400),\"NO2\":(0,175),\"NOx\":(0,420),\n",
        "           \"SO2\":(0,200),\"CO\":(0,8),\"RH\":(0,100),\"WS\":(0,35),\"TEMP\":(-5,45),\"SR\":(0,1.25),\n",
        "           \"BP\":(700,740),\"WD\":(0,360),\"RAINF\":(0,25)},\n",
        "    2023: {\"PM10\":(0,900),\"PM2.5\":(0,800),\"O3\":(0,175),\"NO\":(0,500),\"NO2\":(0,175),\"NOx\":(0,500),\n",
        "           \"SO2\":(0,250),\"CO\":(0,14),\"RH\":(0,100),\"WS\":(0,40),\"TEMP\":(0,45),\"SR\":(0,1),\n",
        "           \"BP\":(690,740),\"WD\":(0,360),\"RAINF\":(0,70)},\n",
        "    2024: {\"PM10\":(0,999),\"PM2.5\":(0,999),\"O3\":(0,180),\"NO\":(0,400),\"NO2\":(0,130),\"NOx\":(0,500),\n",
        "           \"SO2\":(0,150),\"CO\":(0,18),\"RH\":(0,100),\"WS\":(0,38),\"TEMP\":(-4,45.5),\"SR\":(0,1.26),\n",
        "           \"BP\":(687.5,740),\"WD\":(0,360),\"RAINF\":(0,50)},\n",
        "    2025: {\"PM10\":(0,820),\"PM2.5\":(0,350),\"O3\":(0,185),\"NO\":(0,350),\"NO2\":(0,175),\"NOx\":(0,400),\n",
        "           \"SO2\":(0,405),\"CO\":(0,10),\"RH\":(0,100),\"WS\":(0,40),\"TEMP\":(-4.5,45),\"SR\":(0,1.2),\n",
        "           \"BP\":(688,740),\"WD\":(0,360),\"RAINF\":(0,25)}\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================\n",
        "# CHUNK 1: Utilidades (igual 2023)\n",
        "# ==================================\n",
        "def try_parse_datetime(x):\n",
        "    if pd.isna(x): return pd.NaT\n",
        "    if isinstance(x, pd.Timestamp): return x\n",
        "    try:\n",
        "        return pd.to_datetime(x, errors=\"coerce\")\n",
        "    except Exception:\n",
        "        try:\n",
        "            return pd.to_datetime(dtparser.parse(str(x)), errors=\"coerce\")\n",
        "        except Exception:\n",
        "            return pd.NaT\n",
        "\n",
        "def coerce_numeric(series: pd.Series) -> pd.Series:\n",
        "    s = series.astype(str).str.replace(r\"[^\\d\\-\\.,]\", \"\", regex=True).str.strip()\n",
        "    s = pd.Series(np.where(s.str.contains(\",\") & s.str.contains(r\"\\.\"), s.str.replace(\",\", \"\", regex=False), s))\n",
        "    s = pd.Series(np.where((~pd.isna(s)) & (pd.Series(s).str.contains(\",\") & ~pd.Series(s).str.contains(r\"\\.\")),\n",
        "                 pd.Series(s).str.replace(\".\", \"\", regex=False).str.replace(\",\", \".\", regex=False),\n",
        "                 s))\n",
        "    return pd.to_numeric(pd.Series(s), errors=\"coerce\")\n",
        "\n",
        "def standardize_column_names(cols: List[str]) -> List[str]:\n",
        "    mapping = {\n",
        "        r\"^pm\\s*10$\":\"PM10\", r\"^pm10$\":\"PM10\",\n",
        "        r\"^pm\\s*2\\.?5$\":\"PM2.5\", r\"^pm2\\.?5$\":\"PM2.5\",\n",
        "        r\"^o3$\":\"O3\", r\"^no$\":\"NO\", r\"^no2$\":\"NO2\", r\"^nox$\":\"NOx\",\n",
        "        r\"^so2$\":\"SO2\", r\"^co$\":\"CO\", r\"^rh$\":\"RH\", r\"^ws$\":\"WS\",\n",
        "        r\"^(temp|temperature)$\":\"TEMP\", r\"^sr$\":\"SR\", r\"^bp$\":\"BP\",\n",
        "        r\"^wd$\":\"WD\", r\"^(rain|rainf|rainfall|precip.*)$\":\"RAINF\",\n",
        "        r\"^(date|datetime|fecha.*hora|fecha_hora|time.*)$\":TIME_COL,\n",
        "        r\"^(estacion|estaci√≥n|station)$\":\"STATION\",\n",
        "    }\n",
        "    new_cols = []\n",
        "    for c in cols:\n",
        "        c2 = re.sub(r\"\\s+\", \" \", str(c).strip()).upper()\n",
        "        new = c2\n",
        "        for pat, tgt in mapping.items():\n",
        "            if re.match(pat, c2, flags=re.IGNORECASE):\n",
        "                new = tgt; break\n",
        "        new_cols.append(new)\n",
        "    return new_cols\n",
        "\n",
        "def add_station_if_missing(df: pd.DataFrame, station_name: str) -> pd.DataFrame:\n",
        "    if \"STATION\" not in df.columns:\n",
        "        df[\"STATION\"] = station_name\n",
        "    return df\n",
        "\n",
        "def concat_sheets_with_station(xls: pd.ExcelFile, sheet_names: List[str]) -> pd.DataFrame:\n",
        "    dfs = []\n",
        "    for sh in sheet_names:\n",
        "        try:\n",
        "            tmp = xls.parse(sh)\n",
        "            tmp.columns = standardize_column_names(list(tmp.columns))\n",
        "            tmp = add_station_if_missing(tmp, sh)\n",
        "            dfs.append(tmp)\n",
        "        except KeyError as e:\n",
        "            print(f\"Error processing sheet '{sh}': {e}\")\n",
        "            # Optionally, you can choose to skip the problematic sheet or handle the error differently\n",
        "            continue\n",
        "    return pd.concat(dfs, ignore_index=True)"
      ],
      "metadata": {
        "id": "a3yM-5qYbvxu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# CHUNK 2: 2025 ‚Üí Crear TABLA MAESTRA desde 15 sheets\n",
        "# =====================================================\n",
        "assert os.path.exists(PATH_DATA_2025), f\"No se encontr√≥ {PATH_DATA_2025}\"\n",
        "\n",
        "xls_2025 = pd.ExcelFile(PATH_DATA_2025)\n",
        "df_master_2025 = concat_sheets_with_station(xls_2025, xls_2025.sheet_names)\n",
        "\n",
        "# Normaliza nombres, asegura columnas esperadas y parsea DATETIME\n",
        "df_master_2025.columns = standardize_column_names(df_master_2025.columns.tolist())\n",
        "\n",
        "# Keep only expected columns plus TIME_COL and STATION\n",
        "cols_to_keep = EXPECTED_COLS + [TIME_COL, \"STATION\"]\n",
        "df_master_2025 = df_master_2025[[c for c in cols_to_keep if c in df_master_2025.columns]]\n",
        "\n",
        "for c in EXPECTED_COLS:\n",
        "    if c not in df_master_2025.columns:\n",
        "        df_master_2025[c] = np.nan\n",
        "\n",
        "if TIME_COL in df_master_2025.columns:\n",
        "    df_master_2025[TIME_COL] = df_master_2025[TIME_COL].apply(try_parse_datetime)\n",
        "\n",
        "# Apply coerce_numeric to expected columns before saving\n",
        "for c in EXPECTED_COLS:\n",
        "    if c in df_master_2025.columns:\n",
        "        df_master_2025[c] = coerce_numeric(df_master_2025[c])\n",
        "\n",
        "\n",
        "print(\"Dimensi√≥n tabla maestra 2025:\", df_master_2025.shape)\n",
        "print(\"Estaciones detectadas:\", sorted(df_master_2025[\"STATION\"].dropna().unique().tolist())[:20], \"...\")\n",
        "\n",
        "# Guarda la tabla maestra por si quieres usarla despu√©s directamente\n",
        "os.makedirs(\"/content/master\", exist_ok=True)\n",
        "df_master_2025.to_parquet(\"/content/master/aq_2025_master.parquet\", index=False)\n",
        "df_master_2025.to_csv(\"/content/master/aq_2025_master.csv\", index=False)\n",
        "print(\"‚úÖ Master 2025 exportada en /content/master\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sVl-4EFbxdz",
        "outputId": "1028b402-53ec-4b52-ceda-c86e089e07b0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensi√≥n tabla maestra 2025: (64974, 17)\n",
            "Estaciones detectadas: ['CE', 'NE', 'NE2', 'NE3', 'NO', 'NO2', 'NO3', 'NTE', 'NTE2', 'SE', 'SE2', 'SE3', 'SO', 'SO2', 'SUR'] ...\n",
            "‚úÖ Master 2025 exportada en /content/master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CHUNK 3: Funciones del pipeline (igual 2023)\n",
        "# ============================================\n",
        "def describe_variables(df: pd.DataFrame, etiquetas: pd.DataFrame | None) -> pd.DataFrame:\n",
        "    summary = []\n",
        "    for c in df.columns:\n",
        "        ser = df[c]; n_null = int(ser.isna().sum())\n",
        "        if is_datetime64_any_dtype(ser):\n",
        "            tipo = \"Fecha/Hora\"\n",
        "            vals = [pd.to_datetime(ser.min()).isoformat(), pd.to_datetime(ser.max()).isoformat()] if ser.notna().any() else [np.nan, np.nan]\n",
        "        elif is_bool_dtype(ser):\n",
        "            tipo = \"Categ√≥rico (bool)\"; uniq = ser.dropna().unique().tolist(); vals = uniq[:20] + ([\"...\"] if len(uniq) > 20 else [])\n",
        "        elif is_categorical_dtype(ser) or ser.dtype == \"object\":\n",
        "            tipo = \"Categ√≥rico\"; uniq = ser.dropna().unique().tolist(); vals = uniq[:20] + ([\"...\"] if len(uniq) > 20 else [])\n",
        "        elif is_numeric_dtype(ser):\n",
        "            tipo = \"Num√©rico\"\n",
        "            if ser.notna().any():\n",
        "                vmin, vmax = np.nanmin(ser.astype(float)), np.nanmax(ser.astype(float))\n",
        "                vals = [float(vmin), float(vmax)]\n",
        "            else:\n",
        "                vals = [np.nan, np.nan]\n",
        "        else:\n",
        "            tipo = str(ser.dtype); uniq = ser.dropna().unique().tolist(); vals = uniq[:20] + ([\"...\"] if len(uniq) > 20 else [])\n",
        "        summary.append({\"variable\": c, \"descripcion\": None, \"tipo\": tipo, \"valores_posibles\": vals, \"nulos\": n_null})\n",
        "    desc_df = pd.DataFrame(summary)\n",
        "\n",
        "    if etiquetas is not None:\n",
        "        et = etiquetas.copy()\n",
        "        if \"variable\" not in et.columns:\n",
        "            cand = [col for col in et.columns if \"var\" in col.lower() or \"nombre\" in col.lower()]\n",
        "            if cand: et = et.rename(columns={cand[0]: \"variable\"})\n",
        "        for src, dst in [(\"descripcion\",\"descripcion\"),(\"descripci√≥n\",\"descripcion\"),(\"tipo\",\"tipo_usuario\"),\n",
        "                         (\"valores\",\"valores_usuario\"),(\"valores_posibles\",\"valores_usuario\")]:\n",
        "            if src in et.columns and dst not in et.columns: et = et.rename(columns={src: dst})\n",
        "        if \"variable\" in et.columns:\n",
        "            desc_df = desc_df.merge(et, on=\"variable\", how=\"left\")\n",
        "            if \"tipo_usuario\" in desc_df.columns: desc_df[\"tipo\"] = desc_df[\"tipo_usuario\"].fillna(desc_df[\"tipo\"])\n",
        "            if \"valores_usuario\" in desc_df.columns: desc_df[\"valores_posibles\"] = desc_df[\"valores_usuario\"].combine_first(desc_df[\"valores_posibles\"])\n",
        "            for c in [\"tipo_usuario\",\"valores_usuario\"]:\n",
        "                if c in desc_df.columns: desc_df.drop(columns=[c], inplace=True)\n",
        "    return desc_df\n",
        "\n",
        "def quality_checks(df: pd.DataFrame) -> dict:\n",
        "    return {\n",
        "        \"shape\": df.shape,\n",
        "        \"missing_by_col\": df.isna().sum().sort_values(ascending=False).to_dict(),\n",
        "        \"has_infinite\": np.isinf(df.select_dtypes(include=[np.number]).to_numpy()).any(),\n",
        "        \"duplicated_rows\": int(df.duplicated().sum())\n",
        "    }\n",
        "\n",
        "def select_and_explain(df: pd.DataFrame):\n",
        "    keep = [TIME_COL, \"STATION\"] + EXPECTED_COLS\n",
        "    keep = [c for c in keep if c in df.columns]\n",
        "    out = df[keep].copy()\n",
        "    msg = (\"Se seleccionaron DATETIME, STATION y variables est√°ndar; \"\n",
        "           \"se excluyeron columnas auxiliares para evitar ruido.\")\n",
        "    return out, msg\n",
        "\n",
        "def identify_targets(df: pd.DataFrame): return [c for c in [\"PM2.5\",\"PM10\"] if c in df.columns]\n",
        "\n",
        "def fix_types(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Apply coerce_numeric only to columns in EXPECTED_COLS that exist in the DataFrame\n",
        "    for c in EXPECTED_COLS:\n",
        "        if c in df.columns:\n",
        "            df[c] = coerce_numeric(df[c])\n",
        "\n",
        "    if TIME_COL in df.columns:\n",
        "        if not is_datetime64_any_dtype(df[TIME_COL]): df[TIME_COL] = pd.to_datetime(df[TIME_COL], errors=\"coerce\")\n",
        "        df[\"YEAR\"]  = df[TIME_COL].dt.year\n",
        "        df[\"MONTH\"] = df[TIME_COL].dt.month\n",
        "        df[\"DAY\"]   = df[TIME_COL].dt.day\n",
        "        df[\"HOUR\"]  = df[TIME_COL].dt.hour\n",
        "    return df\n",
        "\n",
        "\n",
        "def apply_yearly_ranges(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if \"YEAR\" not in df.columns: return df\n",
        "    def clip_row(row):\n",
        "        yr = row[\"YEAR\"]; ranges = RANGOS_POR_ANIO.get(int(yr) if not pd.isna(yr) else yr, {})\n",
        "        for col, (lo, hi) in ranges.items():\n",
        "            if col in row and pd.notna(row[col]) and (row[col] < lo or row[col] > hi): row[col] = np.nan\n",
        "        return row\n",
        "    return df.apply(clip_row, axis=1)\n",
        "\n",
        "def drop_duplicates(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    b=len(df); df=df.drop_duplicates(); a=len(df); print(f\"Duplicados (exactos): {b-a}\")\n",
        "    if TIME_COL in df.columns and \"STATION\" in df.columns:\n",
        "        b=len(df); df=df.sort_values(TIME_COL).drop_duplicates(subset=[\"STATION\", TIME_COL], keep=\"first\"); a=len(df)\n",
        "        print(f\"Duplicados (STATION, DATETIME): {b-a}\")\n",
        "    return df\n",
        "\n",
        "def iqr_outlier_mask(x: pd.Series, k: float = 1.5):\n",
        "    q1, q3 = np.nanpercentile(x, [25, 75]); iqr = q3-q1; lo, hi = q1-k*iqr, q3+k*iqr\n",
        "    return (x < lo) | (x > hi)\n",
        "\n",
        "def handle_outliers(df: pd.DataFrame, k: float = 1.5) -> pd.DataFrame:\n",
        "    if \"STATION\" not in df.columns or \"YEAR\" not in df.columns: return df\n",
        "    num_cols = [c for c in EXPECTED_COLS if c in df.columns]\n",
        "    def _proc(g):\n",
        "        for c in num_cols:\n",
        "            s=g[c]\n",
        "            if s.notna().sum()>=12:\n",
        "                g.loc[iqr_outlier_mask(s,k), c]=np.nan\n",
        "        return g\n",
        "    return df.groupby([\"STATION\",\"YEAR\"], group_keys=False).apply(_proc)\n",
        "\n",
        "def handle_missing(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    num_cols = [c for c in df.columns if c in EXPECTED_COLS]\n",
        "    if TIME_COL in df.columns and \"STATION\" in df.columns:\n",
        "        def _interp(g):\n",
        "            g=g.sort_values(TIME_COL).set_index(TIME_COL)\n",
        "            for c in num_cols:\n",
        "                s=g[c].interpolate(method=\"time\").ffill().bfill()\n",
        "                g[c]=s\n",
        "            return g.reset_index()\n",
        "        df=df.groupby(\"STATION\", group_keys=False).apply(_interp)\n",
        "    if IMPUTE_STRATEGY in (\"mean\",\"median\"):\n",
        "        imputer=SimpleImputer(strategy=IMPUTE_STRATEGY)\n",
        "        df[num_cols]=imputer.fit_transform(df[num_cols])\n",
        "    return df\n",
        "\n",
        "def handle_categoricals(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    cat_cols=[c for c in df.columns if df[c].dtype==\"object\" or str(df[c].dtype).startswith(\"category\")]\n",
        "    return pd.get_dummies(df, columns=cat_cols, drop_first=True, dtype=int) if CREATE_DUMMIES and cat_cols else df\n",
        "\n",
        "def build_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    out=df.copy()\n",
        "    if \"WS\" in out.columns and \"WD\" in out.columns:\n",
        "        ws=out[\"WS\"].astype(float); wd=np.deg2rad(out[\"WD\"].astype(float))\n",
        "        out[\"WIND_U\"]=-ws*np.sin(wd); out[\"WIND_V\"]=-ws*np.cos(wd)\n",
        "    if TIME_COL in out.columns:\n",
        "        out[\"WEEKDAY\"]=out[TIME_COL].dt.weekday; out[\"IS_WEEKEND\"]=(out[\"WEEKDAY\"]>=5).astype(int)\n",
        "    return out\n",
        "\n",
        "def scale_numeric(df: pd.DataFrame):\n",
        "    if SCALING not in (\"standard\",\"minmax\"): return df, {}\n",
        "    cols=[c for c in (EXPECTED_COLS+[\"WIND_U\",\"WIND_V\"]) if c in df.columns]\n",
        "    scaler=StandardScaler() if SCALING==\"standard\" else MinMaxScaler()\n",
        "    out=df.copy(); out[cols]=scaler.fit_transform(out[cols]); return out, {\"scaler\":SCALING,\"columns\":cols}\n",
        "\n",
        "def bin_numeric(df: pd.DataFrame, cols: List[str]):\n",
        "    if BINNING not in (\"quantile\",\"uniform\") or not cols: return df, {}\n",
        "    b=KBinsDiscretizer(n_bins=N_BINS, encode=\"ordinal\", strategy=(\"quantile\" if BINNING==\"quantile\" else \"uniform\"))\n",
        "    x=df[cols]; mask=x.notna().all(axis=1); out=df.copy()\n",
        "    out.loc[mask,[f\"{c}_BIN\" for c in cols]]=b.fit_transform(x[mask])\n",
        "    return out, {\"binner\":BINNING,\"columns\":cols,\"bins\":N_BINS}\n",
        "\n",
        "def tidy_and_export(df: pd.DataFrame, outdir=\"/content/clean_2025\"):\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    df.to_parquet(os.path.join(outdir,\"air_quality_2025_clean_full.parquet\"), index=False)\n",
        "    if \"YEAR\" in df.columns:\n",
        "        for yr, dfg in df.groupby(\"YEAR\"):\n",
        "            dfg.to_csv(os.path.join(outdir, f\"air_quality_2025_clean_{int(yr)}.csv\"), index=False)\n",
        "    if \"STATION\" in df.columns and \"YEAR\" in df.columns:\n",
        "        for (st, yr), dfg in df.groupby([\"STATION\",\"YEAR\"]):\n",
        "            fname=re.sub(r\"[^A-Za-z0-9\\-]+\",\"_\", str(st))\n",
        "            dfg.to_csv(os.path.join(outdir, f\"clean_{fname}_{int(yr)}.csv\"), index=False)\n",
        "    print(\"üì¶ Exportado en:\", outdir)"
      ],
      "metadata": {
        "id": "XnuRViNUbzlr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================================\n",
        "# CHUNK 4: Ejecutar pipeline sobre 2025\n",
        "# =======================================\n",
        "print(\"=== 2025: Comprensi√≥n de los datos ===\")\n",
        "etiquetas = pd.read_excel(PATH_ETIQUETAS) if os.path.exists(PATH_ETIQUETAS) else None\n",
        "print(\"Dimensi√≥n maestra 2025:\", df_master_2025.shape)\n",
        "\n",
        "desc = describe_variables(df_master_2025, etiquetas)\n",
        "display(desc.head(30))\n",
        "\n",
        "qc = quality_checks(df_master_2025)\n",
        "print(\"Calidad:\")\n",
        "print(\" - Registros/Columnas:\", qc[\"shape\"])\n",
        "print(\" - Faltantes (top10):\", dict(list(qc[\"missing_by_col\"].items())[:10]))\n",
        "print(\" - Infinitos:\", qc[\"has_infinite\"])\n",
        "print(\" - Duplicados:\", qc[\"duplicated_rows\"])\n",
        "\n",
        "print(\"\\n=== 2025: Preparaci√≥n ===\")\n",
        "df, rationale = select_and_explain(df_master_2025)\n",
        "print(\"Racional:\\n\", rationale)\n",
        "\n",
        "df = fix_types(df)\n",
        "df = apply_yearly_ranges(df)      # aplica rangos del a√±o 2025\n",
        "df = drop_duplicates(df)\n",
        "df = handle_outliers(df, k=1.5)\n",
        "df = handle_missing(df)\n",
        "\n",
        "targets = identify_targets(df)\n",
        "print(\"Targets sugeridos:\", targets)\n",
        "\n",
        "df = handle_categoricals(df)\n",
        "\n",
        "print(\"\\n=== 2025: Transformaci√≥n ===\")\n",
        "df = build_features(df)\n",
        "df_scaled, scale_info = scale_numeric(df)\n",
        "if scale_info: print(\"Escalado:\", scale_info)\n",
        "\n",
        "bin_cols = [c for c in [\"PM2.5\",\"PM10\"] if c in df_scaled.columns]\n",
        "df_final, bin_info = bin_numeric(df_scaled, bin_cols)\n",
        "if bin_info: print(\"Binning:\", bin_info)\n",
        "\n",
        "print(\"\\n=== 2025: Reformateo / Exportaci√≥n ===\")\n",
        "tidy_and_export(df_final)\n",
        "\n",
        "print(\"\\n=== Resumen 2025 ===\")\n",
        "print(\"Shape final:\", df_final.shape)\n",
        "print(\"NA totales:\", int(df_final.isna().sum().sum()))\n",
        "print(\"Features derivadas:\", [c for c in [\"WIND_U\",\"WIND_V\",\"WEEKDAY\",\"IS_WEEKEND\"] if c in df_final.columns])\n",
        "print(\"‚úÖ Listo para an√°lisis como la versi√≥n 2023.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WQ_KPmF-b2Dx",
        "outputId": "559c396d-7528-4317-8130-6700b3435a9e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== 2025: Comprensi√≥n de los datos ===\n",
            "Dimensi√≥n maestra 2025: (64974, 17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1214294706.py:13: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  elif is_categorical_dtype(ser) or ser.dtype == \"object\":\n",
            "/tmp/ipython-input-1214294706.py:13: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  elif is_categorical_dtype(ser) or ser.dtype == \"object\":\n",
            "/tmp/ipython-input-1214294706.py:13: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  elif is_categorical_dtype(ser) or ser.dtype == \"object\":\n",
            "/tmp/ipython-input-1214294706.py:13: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  elif is_categorical_dtype(ser) or ser.dtype == \"object\":\n",
            "/tmp/ipython-input-1214294706.py:13: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  elif is_categorical_dtype(ser) or ser.dtype == \"object\":\n",
            "/tmp/ipython-input-1214294706.py:13: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  elif is_categorical_dtype(ser) or ser.dtype == \"object\":\n",
            "/tmp/ipython-input-1214294706.py:13: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  elif is_categorical_dtype(ser) or ser.dtype == \"object\":\n",
            "/tmp/ipython-input-1214294706.py:13: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  elif is_categorical_dtype(ser) or ser.dtype == \"object\":\n",
            "/tmp/ipython-input-1214294706.py:13: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  elif is_categorical_dtype(ser) or ser.dtype == \"object\":\n",
            "/tmp/ipython-input-1214294706.py:13: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  elif is_categorical_dtype(ser) or ser.dtype == \"object\":\n",
            "/tmp/ipython-input-1214294706.py:13: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  elif is_categorical_dtype(ser) or ser.dtype == \"object\":\n",
            "/tmp/ipython-input-1214294706.py:13: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  elif is_categorical_dtype(ser) or ser.dtype == \"object\":\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    variable descripcion        tipo  \\\n",
              "0       PM10        None    Num√©rico   \n",
              "1      PM2.5        None    Num√©rico   \n",
              "2         O3        None    Num√©rico   \n",
              "3         NO        None    Num√©rico   \n",
              "4        NO2        None    Num√©rico   \n",
              "5        NOx        None    Num√©rico   \n",
              "6        SO2        None    Num√©rico   \n",
              "7         CO        None    Num√©rico   \n",
              "8         RH        None    Num√©rico   \n",
              "9         SR        None    Num√©rico   \n",
              "10     RAINF        None    Num√©rico   \n",
              "11  DATETIME        None  Fecha/Hora   \n",
              "12   STATION        None  Categ√≥rico   \n",
              "13        WS        None    Num√©rico   \n",
              "14      TEMP        None    Num√©rico   \n",
              "15        BP        None    Num√©rico   \n",
              "16        WD        None    Num√©rico   \n",
              "\n",
              "                                     valores_posibles  nulos  \n",
              "0                                        [2.0, 811.0]   2537  \n",
              "1                                       [0.0, 340.25]  24036  \n",
              "2                                        [0.5, 184.0]   3608  \n",
              "3                                        [0.5, 325.6]  13847  \n",
              "4                                        [0.1, 165.1]  12640  \n",
              "5                                        [0.5, 399.9]  11600  \n",
              "6                                        [0.5, 404.7]   6945  \n",
              "7                                        [0.05, 9.79]   8218  \n",
              "8                                        [0.0, 100.0]   9471  \n",
              "9                                       [-0.008, 2.0]   3888  \n",
              "10                                        [0.0, 18.4]   3683  \n",
              "11         [2025-01-01T00:00:00, 2025-06-30T23:00:00]     15  \n",
              "12  [SE, CE, SO, NE2, SE2, SE3, NE, NO, NO2, NTE, ...      0  \n",
              "13                                         [nan, nan]  64974  \n",
              "14                                         [nan, nan]  64974  \n",
              "15                                         [nan, nan]  64974  \n",
              "16                                         [nan, nan]  64974  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97e141a6-4338-4013-9d2a-13f810f2e517\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>variable</th>\n",
              "      <th>descripcion</th>\n",
              "      <th>tipo</th>\n",
              "      <th>valores_posibles</th>\n",
              "      <th>nulos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PM10</td>\n",
              "      <td>None</td>\n",
              "      <td>Num√©rico</td>\n",
              "      <td>[2.0, 811.0]</td>\n",
              "      <td>2537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PM2.5</td>\n",
              "      <td>None</td>\n",
              "      <td>Num√©rico</td>\n",
              "      <td>[0.0, 340.25]</td>\n",
              "      <td>24036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O3</td>\n",
              "      <td>None</td>\n",
              "      <td>Num√©rico</td>\n",
              "      <td>[0.5, 184.0]</td>\n",
              "      <td>3608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NO</td>\n",
              "      <td>None</td>\n",
              "      <td>Num√©rico</td>\n",
              "      <td>[0.5, 325.6]</td>\n",
              "      <td>13847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NO2</td>\n",
              "      <td>None</td>\n",
              "      <td>Num√©rico</td>\n",
              "      <td>[0.1, 165.1]</td>\n",
              "      <td>12640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NOx</td>\n",
              "      <td>None</td>\n",
              "      <td>Num√©rico</td>\n",
              "      <td>[0.5, 399.9]</td>\n",
              "      <td>11600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SO2</td>\n",
              "      <td>None</td>\n",
              "      <td>Num√©rico</td>\n",
              "      <td>[0.5, 404.7]</td>\n",
              "      <td>6945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>CO</td>\n",
              "      <td>None</td>\n",
              "      <td>Num√©rico</td>\n",
              "      <td>[0.05, 9.79]</td>\n",
              "      <td>8218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RH</td>\n",
              "      <td>None</td>\n",
              "      <td>Num√©rico</td>\n",
              "      <td>[0.0, 100.0]</td>\n",
              "      <td>9471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SR</td>\n",
              "      <td>None</td>\n",
              "      <td>Num√©rico</td>\n",
              "      <td>[-0.008, 2.0]</td>\n",
              "      <td>3888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RAINF</td>\n",
              "      <td>None</td>\n",
              "      <td>Num√©rico</td>\n",
              "      <td>[0.0, 18.4]</td>\n",
              "      <td>3683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>DATETIME</td>\n",
              "      <td>None</td>\n",
              "      <td>Fecha/Hora</td>\n",
              "      <td>[2025-01-01T00:00:00, 2025-06-30T23:00:00]</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>STATION</td>\n",
              "      <td>None</td>\n",
              "      <td>Categ√≥rico</td>\n",
              "      <td>[SE, CE, SO, NE2, SE2, SE3, NE, NO, NO2, NTE, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>WS</td>\n",
              "      <td>None</td>\n",
              "      <td>Num√©rico</td>\n",
              "      <td>[nan, nan]</td>\n",
              "      <td>64974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>TEMP</td>\n",
              "      <td>None</td>\n",
              "      <td>Num√©rico</td>\n",
              "      <td>[nan, nan]</td>\n",
              "      <td>64974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>BP</td>\n",
              "      <td>None</td>\n",
              "      <td>Num√©rico</td>\n",
              "      <td>[nan, nan]</td>\n",
              "      <td>64974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>WD</td>\n",
              "      <td>None</td>\n",
              "      <td>Num√©rico</td>\n",
              "      <td>[nan, nan]</td>\n",
              "      <td>64974</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97e141a6-4338-4013-9d2a-13f810f2e517')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-97e141a6-4338-4013-9d2a-13f810f2e517 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-97e141a6-4338-4013-9d2a-13f810f2e517');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b7b062de-c908-498e-a59e-6788722bc7ae\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b7b062de-c908-498e-a59e-6788722bc7ae')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b7b062de-c908-498e-a59e-6788722bc7ae button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calidad:\n",
            " - Registros/Columnas: (64974, 17)\n",
            " - Faltantes (top10): {'WS': 64974, 'BP': 64974, 'TEMP': 64974, 'WD': 64974, 'PM2.5': 24036, 'NO': 13847, 'NO2': 12640, 'NOx': 11600, 'RH': 9471, 'CO': 8218}\n",
            " - Infinitos: False\n",
            " - Duplicados: 0\n",
            "\n",
            "=== 2025: Preparaci√≥n ===\n",
            "Racional:\n",
            " Se seleccionaron DATETIME, STATION y variables est√°ndar; se excluyeron columnas auxiliares para evitar ruido.\n",
            "Duplicados (exactos): 0\n",
            "Duplicados (STATION, DATETIME): 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1214294706.py:105: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return df.groupby([\"STATION\",\"YEAR\"], group_keys=False).apply(_proc)\n",
            "/tmp/ipython-input-1214294706.py:116: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df=df.groupby(\"STATION\", group_keys=False).apply(_interp)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Targets sugeridos: ['PM2.5', 'PM10']\n",
            "\n",
            "=== 2025: Transformaci√≥n ===\n",
            "Escalado: {'scaler': 'standard', 'columns': ['PM10', 'PM2.5', 'O3', 'NO', 'NO2', 'NOx', 'SO2', 'CO', 'RH', 'WS', 'TEMP', 'SR', 'BP', 'WD', 'RAINF', 'WIND_U', 'WIND_V']}\n",
            "\n",
            "=== 2025: Reformateo / Exportaci√≥n ===\n",
            "üì¶ Exportado en: /content/clean_2025\n",
            "\n",
            "=== Resumen 2025 ===\n",
            "Shape final: (64959, 38)\n",
            "NA totales: 407034\n",
            "Features derivadas: ['WIND_U', 'WIND_V', 'WEEKDAY', 'IS_WEEKEND']\n",
            "‚úÖ Listo para an√°lisis como la versi√≥n 2023.\n"
          ]
        }
      ]
    }
  ]
}